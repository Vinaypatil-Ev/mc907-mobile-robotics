{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Mc907/Mo651 - Mobile Robotics\n",
    "\n",
    "### Student:\n",
    "Luiz Eduardo Cartolano - RA: 183012\n",
    "\n",
    "### Instructor:\n",
    "Esther Luna Colombini\n",
    "\n",
    "### Github Link:\n",
    "[Project Repository](https://github.com/luizcartolano2/mc907-mobile-robotics)\n",
    "\n",
    "### Subject of this Work:\n",
    "The general objective of this work is to implement and evaluate at least 1 robot control behavior per group member.\n",
    "\n",
    "### Goals:\n",
    "1. Implement and evaluate at least 1 robot control behavior per group member (AvoidObstacle, WallFollow, Go- ToGoal) using models based on PID, Fuzzy, Neural Networks, etc;\n",
    "2. Propose a behavior coordination strategy (state machine, planner, AR, subsumption, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Starts Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import vrep\n",
    "import sys, time\n",
    "from src import robot as rb\n",
    "from src.utils import vrep2array\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import skfuzzy\n",
    "import skfuzzy as fuzz\n",
    "import skfuzzy.control as ctrl\n",
    "from reinforcement_learning.train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the kinematic model of the Pionner P3DX\n",
    "For this project, we are going to use the configuration of the mobile robot being characterized by the position (x,y) and the orientation in a Cartesian coordinate.\n",
    "\n",
    "Using the follow parameters:\n",
    "1. $V_R$: linear velocity of the right wheel.\n",
    "2. $V_L$: linear velocity of the left wheel.\n",
    "3. $W$: angular velocity of the mobile robot.\n",
    "4. $X$: abscissa of the robot.\n",
    "5. $Y$: intercept of the robot.\n",
    "6. $X,Y$ : the actual position coordinates.\n",
    "7. $\\theta$: orientation of the robot.\n",
    "8. $L$: the distance between the driving wheels.\n",
    "\n",
    "The kinematic model is given by these equations [1](https://www.hindawi.com/journals/cin/2016/9548482/abs/):\n",
    "<br>\n",
    "\\begin{align}\n",
    "\\frac{dX}{dt} & = \\frac{V_L + V_R}{2} \\cdot cos(\\theta) \\\\\n",
    "\\frac{dY}{dt} & = \\frac{V_L + V_R}{2} \\cdot sen(\\theta) \\\\\n",
    "\\frac{d \\theta}{dt} & = \\frac{V_L - V_R}{2} \\\\\n",
    "\\end{align}\n",
    "<br>\n",
    "Where ($X$,$Y$ and $\\theta$) are the robot actual position and orientation angle in world reference frame. In simulation, we use the discrete form to build a model of the robot. The discrete form of the kinematic model is given by the following equations:<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "X_{k+1} & = X_k + T \\cdot \\frac{V_{lk} + V_{rk}}{2} \\cdot cos(\\theta_k + \\frac{d \\theta}{dt} ) \\\\\n",
    "Y_{k+1} & = Y_k + T \\cdot \\frac{V_{lk} + V_{rk}}{2} \\cdot sen(\\theta_k + \\frac{d \\theta}{dt}) \\\\\n",
    "\\theta_{k+1} & = \\theta_k + T \\cdot \\frac{V_{lk} + V_{rk}}{L} \\\\\n",
    "\\end{align}\n",
    "<br>\n",
    "\n",
    "where $X_{k+1}$ and $Y_{k+1}$ represent the position of the center axis of the mobile robot and $T$ is the sampling time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pose:\n",
    "    \"\"\"\n",
    "    A class used to store the robot pose.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    x : double\n",
    "        The x position of the robot on the map\n",
    "    y : double\n",
    "        The y position of the robot on the map\n",
    "    orientation : double\n",
    "        The angle theta of the robot on the map\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    The class doesn't have any methods\n",
    "    \"\"\"\n",
    "    def __init__(self, x=None, y=None, orientation=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.orientation = orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Odometry():\n",
    "    \"\"\"\n",
    "    A class used to implement methods that allow a robot to calculate his own odometry.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    robot : obj\n",
    "        The robot object\n",
    "    lastPose : obj Pose\n",
    "        Store the robot's pose during his movement\n",
    "    lastTimestamp : time\n",
    "        Store the last timestamp\n",
    "    left_vel : double\n",
    "        Store the velocity of the left robot wheel\n",
    "    right_vel : double\n",
    "        Store the velocity of the right robot wheel\n",
    "    delta_time : double\n",
    "        Store how much time has passed\n",
    "    delta_theta : double\n",
    "        Store how the orientation change\n",
    "    delta_space : double\n",
    "        Store how the (x,y) change\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    ground_truth_updater()\n",
    "        Function to update the ground truth, the real pose of the robot at the simulator\n",
    "    odometry_pose_updater()\n",
    "        Function to estimate the pose of the robot based on the kinematic model \n",
    "    \"\"\"\n",
    "    def __init__(self, robot):\n",
    "        self.robot = robot\n",
    "        self.lastPose = None\n",
    "        self.lastTimestamp = time()\n",
    "        self.left_vel = 0\n",
    "        self.right_vel = 0\n",
    "        self.delta_time = 0\n",
    "        self.delta_theta = 0\n",
    "        self.delta_space = 0\n",
    "        \n",
    "    def ground_truth_updater(self):\n",
    "        \"\"\"\n",
    "            Function to update the ground truth, the real pose of the robot at the simulator\n",
    "        \"\"\"\n",
    "        # get the (x,y,z) position of the robot at the simulator\n",
    "        pose = self.robot.get_current_position()\n",
    "        # get the orientation of the robot (euler angles)\n",
    "        orientation = self.robot.get_current_orientation()\n",
    "        \n",
    "        # return an pose object (x,y,theta)\n",
    "        return Pose(x=pose[0], y=pose[1], orientation=orientation[2])\n",
    "    \n",
    "    def odometry_pose_updater(self):\n",
    "        \"\"\"\n",
    "            Function to estimate the pose of the robot based on the knematic model\n",
    "        \"\"\"\n",
    "        if self.lastPose is None:\n",
    "            self.lastPose = self.ground_truth_updater()\n",
    "            return self.lastPose\n",
    "            \n",
    "        # get the actual timestamp\n",
    "        time_now = time()\n",
    "        # get the robot linear velocity for the left and right wheel\n",
    "        left_vel, right_vel = self.robot.get_linear_velocity()\n",
    "        # calculate the difference between the acutal and last timestamp\n",
    "        delta_time = time_now - self.lastTimestamp\n",
    "        # calculate the angle deslocation - based on the kinematic model\n",
    "        delta_theta = (right_vel - left_vel) * (delta_time / self.robot.ROBOT_WIDTH)\n",
    "        # calculate the distance deslocation - based on the kinematic model\n",
    "        delta_space = (right_vel + left_vel) * (delta_time / 2)\n",
    "        \n",
    "        # auxiliary function to sum angles\n",
    "        add_deltha = lambda start, delta: (((start+delta)%(2*math.pi))-(2*math.pi)) if (((start+delta)%(2*math.pi))>math.pi) else ((start+delta)%(2*math.pi))\n",
    "\n",
    "        # calculate the new X pose\n",
    "        x = self.lastPose.x + (delta_space * math.cos(add_deltha(self.lastPose.orientation, delta_theta/2)))\n",
    "        # calculate the new Y pose\n",
    "        y = self.lastPose.y + (delta_space * math.sin(add_deltha(self.lastPose.orientation, delta_theta/2)))\n",
    "        # calculate the new Orientation pose\n",
    "        theta = add_deltha(self.lastPose.orientation, delta_theta)\n",
    "        \n",
    "        # uptade the state of the class\n",
    "        self.lastPose = Pose(x, y, theta)\n",
    "        self.lastTimestamp = time_now\n",
    "        self.left_vel = left_vel\n",
    "        self.right_vel = right_vel\n",
    "        self.delta_time = delta_time\n",
    "        self.delta_theta = delta_theta\n",
    "        self.delta_space = delta_space\n",
    "        \n",
    "        return self.lastPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the class that controls the robot walker\n",
    "\n",
    "For this project we are going to use two different controllers in order to make the robot avoid obstacles in the map. The first one is a classical fuzzy based system, and the second one, is a more modern approach, based on artificial intelligence, called reinforcement learning.\n",
    "\n",
    "### Controllers:\n",
    "**1. Fuzzy**\n",
    "   \n",
    "   Fuzzy logic is a very common technique in the Artificial Intelligence branch. It is a method that introduces the concept of partially correct and / or wrong, different from Boolean logic, in which only binary values ​​are allowed. This fact allows generalist logic in which it is not necessary to deal with all possible cases, ideal for applications with limited memory and / or time.\n",
    "\n",
    "   A fuzzy control system is a control system based on fuzzy logic—a mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true or false, respectively).\n",
    "   \n",
    "   The input variables in a fuzzy control system are in general mapped by sets of membership functions similar to this, known as \"fuzzy sets\". The process of converting a crisp input value to a fuzzy value is called \"fuzzification\". A control system may also have various types of switch, or \"ON-OFF\", inputs along with its analog inputs, and such switch inputs of course will always have a truth value equal to either 1 or 0, but the scheme can deal with them as simplified fuzzy functions that happen to be either one value or another. Given \"mappings\" of input variables into membership functions and truth values, the microcontroller then makes decisions for what action to take, based on a set of \"rules\", each of the form:\n",
    "~~~\n",
    "    IF brake temperature IS warm AND speed IS not very fast\n",
    "    THEN brake pressure IS slightly decreased.\n",
    "~~~\n",
    "\n",
    "   For this project the implemented fuzzy was very simples, and aims just to make the robot abble to avoid obstacles on his way. He uses the ultrassonic sensors for his three inputs (front, left and right distance) and outputs the linear velocity for both weels.\n",
    "   \n",
    "   Some fundamental concepts to understand logic are:\n",
    "    \n",
    "1. **Degree of Relevance:** value in the range $[0,1]$ that determines the degree to which a given element belongs to a set, allowing a gradual transition from falsehood to truth.\n",
    "2. **Fuzzy Set:** A set A in X is expressed as a set of ordered pairs: $A = {{(x, \\mu_A (X)) | x \\in X }}$.\n",
    "3. **Fuzzy Rules:** are created to evaluate the antecedent (input) and apply the result to the consequent (output). They are partially activated depending on the antecedent.\n",
    "4. **Fuzzy Steps:** \n",
    "    1. *Fuzification:* stage in which subjective linguistic variables and pertinence functions are defined.\n",
    "    2. *Inference:* stage at which rules are defined and evaluated.\n",
    "    3. *Defuzification:* step in which the resulting regions are converted to values for the system output variable. The best known methods of defuzification are: centroid, bisector, lowest of maximum (SOM), middle of maximum (MOM), highest of maximum (LOM).\n",
    "\n",
    "Now, we are given a more detailed explanation about the implemented system, showing how we model the inputs, outputs, system rules and the defuzzify methods. \n",
    "   \n",
    "1. **Inputs and Outputs:** For this fuzzy we use three antecedents (all of them has the same shape of the one show bellow) and two consequents. The antecedents works mapping the left, right and front sensors of the ultrassonic sensors of the robot. As we can see, inputs are divide in three sets, low, medium and high distances that aims to tell the system how far he is from some object in the map. The consequents, by the other side, aims to mapping the velocity of both wheels of the robot, they are split in four velocities.\n",
    "    Fuzzy Antecedent        |  Fuzzy Consequent\n",
    "    :-------------------------:|:-------------------------:\n",
    "    ![](images/input.png)  |  ![](images/output.png)\n",
    "2. **Rules:** The system is implemented using eleven rules, that we enough to make the robot able to escape from obstacles from the map with a stable control. The rules can be describe as follow:\n",
    "~~~\n",
    "        left['low'] AND right['low'] AND (front['medium'] OR front['far'])),\n",
    "        output_left['low'], output_right['low']\n",
    "\n",
    "        left['low'] AND right['low'] AND front['low'],\n",
    "        output_left['reverse'], output_right['low']\n",
    "\n",
    "        left['medium'] OR left['far'] AND right['low'] AND front['low'],\n",
    "        output_left['low'], output_right['high']\n",
    "\n",
    "        left['medium'] OR left['far'] AND right['low'] AND front['medium'] OR front['far'],\n",
    "        output_left['low'], output_right['high']\n",
    "\n",
    "        left['far'] AND right['medium'] AND front['low'],\n",
    "        output_left['low'], output_right['high']\n",
    "\n",
    "        left['far'] AND right['far'] AND front['low'],\n",
    "        output_left['high'], output_right['low']\n",
    "\n",
    "        left['medium'] AND right['medium'] AND front['low'],\n",
    "        output_left['high'], output_right['low']\n",
    "\n",
    "        left['medium'] AND right['far'] AND front['low'],\n",
    "        output_left['high'], output_right['low']\n",
    "\n",
    "        left['low'] AND right['medium'] OR right['far'] AND front['low'],\n",
    "        output_left['high'], output_right['low']\n",
    "\n",
    "        left['low'] AND right['medium'] OR right['far'] AND front['medium'] OR front['far'],\n",
    "        output_left['high'], output_right['low']\n",
    "\n",
    "        left['medium'] OR left['far'] AND right['medium'] OR right['far'] AND front['medium'] OR front['far'],\n",
    "        output_left['medium'], output_right['medium']\n",
    "~~~\n",
    "    \n",
    "3. **Defuzzification:** In order to have a more conservative controller we used the minimum of the maximuns (SOM) as the defuzzification method, the consequences of this approach will be commented at the Results section.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyControler():\n",
    "    \"\"\"\n",
    "    A class used to implement methods that allow a robot to walk, based on a fuzzy logic controller.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    forward: skfuzzy object\n",
    "        Skfuzzy input object\n",
    "    left: skfuzzy object\n",
    "        Skfuzzy input object    \n",
    "    right: skfuzzy object\n",
    "        Skfuzzy input object    \n",
    "    output_left: skfuzzy object\n",
    "        Skfuzzy output object\n",
    "    output_right: skfuzzy object\n",
    "        Skfuzzy output object    \n",
    "    rules: skfuzzy object\n",
    "        List of rules to the fuzzy\n",
    "    control: skfuzzy object\n",
    "        Skfuzzy controller object\n",
    "    simulator: skfuzzy object\n",
    "        Skfuzzy simulator object\n",
    "\n",
    "    Methods:\n",
    "    \n",
    "    -------\n",
    "    create_inputs()\n",
    "        Function to create skfuzzy input functions\n",
    "    create_outputs()\n",
    "        Function to create skfuzzy output functions        \n",
    "    create_rules()\n",
    "        Function to create skfuzzy rules\n",
    "    create_control()\n",
    "        Function to create skfuzzy controller\n",
    "    show_fuzzy()\n",
    "        Function to show the fuzzy rules as a graph\n",
    "    create_simulator()\n",
    "        Function that controls the fuzzy pipeline\n",
    "    simulate()\n",
    "        Function that give outputs velocity based on input distance\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, behavior):\n",
    "        self.front = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.output_left = None\n",
    "        self.output_right = None\n",
    "        self.rules = []\n",
    "        self.control = None\n",
    "        self.simulator = None\n",
    "        self.behavior = behavior\n",
    "    \n",
    "    def create_inputs(self):\n",
    "        # set the variable universe as near, medium and far\n",
    "        self.front = ctrl.Antecedent(np.arange(0, 5.01, 0.01), 'front')\n",
    "        self.front['low'] = fuzz.trapmf(self.front.universe, [0, 0, 0.6, 1])\n",
    "        self.front['medium'] = fuzz.trimf(self.front.universe, [0.6, 1, 1.4])\n",
    "        self.front['far'] = fuzz.trapmf(self.front.universe, [1, 1.5, 5, 5])\n",
    "        \n",
    "        self.left = ctrl.Antecedent(np.arange(0, 5.01, 0.01), 'left')\n",
    "        self.left['low'] = fuzz.trapmf(self.left.universe, [0, 0, 0.6, 1])\n",
    "        self.left['medium'] = fuzz.trimf(self.left.universe, [0.6, 1, 1.4])\n",
    "        self.left['far'] = fuzz.trapmf(self.left.universe, [1, 1.5, 5, 5])\n",
    "\n",
    "        self.right = ctrl.Antecedent(np.arange(0, 5.01, 0.01), 'right')\n",
    "        self.right['low'] = fuzz.trapmf(self.right.universe, [0, 0, 0.6, 1])\n",
    "        self.right['medium'] = fuzz.trimf(self.right.universe, [0.6, 1, 1.4])\n",
    "        self.right['far'] = fuzz.trapmf(self.right.universe, [1, 1.5, 5, 5])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def create_outputs(self):\n",
    "        \n",
    "        self.output_left = ctrl.Consequent(np.arange(-1, 2.01, 0.1), 'output_left')\n",
    "        self.output_left['reverse'] = fuzz.trapmf(self.output_left.universe, [-1,-1, 0, 0.2])\n",
    "        self.output_left['low'] = fuzz.trimf(self.output_left.universe, [0,1, 1.3])\n",
    "        self.output_left['medium'] = fuzz.trimf(self.output_left.universe, [1,1.5, 1.75])\n",
    "        self.output_left['high'] = fuzz.trimf(self.output_left.universe, [1.2,1.8, 2])\n",
    "        self.output_left.defuzzify_method = 'som'\n",
    "        \n",
    "        self.output_right = ctrl.Consequent(np.arange(-1, 2.01, 0.1), 'output_right')\n",
    "        self.output_right['reverse'] = fuzz.trapmf(self.output_left.universe, [-1,-1, 0, 0.2])\n",
    "        self.output_right['low'] = fuzz.trimf(self.output_left.universe, [0,1, 1.3])\n",
    "        self.output_right['medium'] = fuzz.trimf(self.output_left.universe, [1,1.5, 1.75])\n",
    "        self.output_right['high'] = fuzz.trimf(self.output_left.universe, [1.2,1.8, 2])\n",
    "        self.output_right.defuzzify_method = 'som'\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def create_rules(self, front, left, right, output_left, output_right):\n",
    "\n",
    "        rule1 = ctrl.Rule(antecedent=(left['low'] & right['low'] & (front['medium'] | front['far'])),\n",
    "              consequent=(output_left['low'], output_right['low']))\n",
    "\n",
    "        rule2 = ctrl.Rule(antecedent=(left['low'] & right['low'] & front['low']),\n",
    "              consequent=(output_left['reverse'], output_right['low']))\n",
    "\n",
    "        rule3 = ctrl.Rule(antecedent=((left['medium'] | left['far']) & right['low'] & front['low']),\n",
    "              consequent=(output_left['low'], output_right['high']))\n",
    "\n",
    "        rule4 = ctrl.Rule(antecedent=((left['medium'] | left['far']) & right['low'] & (front['medium'] | front['far'])),\n",
    "              consequent=(output_left['low'], output_right['high']))\n",
    "\n",
    "        rule5 = ctrl.Rule(antecedent=(left['far'] & right['medium'] & front['low']),\n",
    "              consequent=(output_left['low'], output_right['high']))\n",
    "\n",
    "        rule6 = ctrl.Rule(antecedent=(left['far'] & right['far'] & front['low']),\n",
    "              consequent=(output_left['high'], output_right['low']))\n",
    "\n",
    "        rule7 = ctrl.Rule(antecedent=(left['medium'] & right['medium'] & front['low']),\n",
    "              consequent=(output_left['high'], output_right['low']))\n",
    "\n",
    "        rule8 = ctrl.Rule(antecedent=(left['medium'] & right['far'] & front['low']),\n",
    "              consequent=(output_left['high'], output_right['low']))\n",
    "\n",
    "        rule9 = ctrl.Rule(antecedent=(left['low'] & (right['medium'] | right['far']) & front['low']),\n",
    "              consequent=(output_left['high'], output_right['low']))\n",
    "\n",
    "        rule10 = ctrl.Rule(antecedent=(left['low'] & (right['medium'] | right['far']) & (front['medium'] | front['far'])),\n",
    "              consequent=(output_left['high'], output_right['low']))\n",
    "\n",
    "        rule11 = ctrl.Rule(antecedent=((left['medium'] | left['far']) & (right['medium'] | right['far']) & (front['medium'] | front['far'])),\n",
    "              consequent=(output_left['medium'], output_right['medium']))\n",
    "\n",
    "        for i in range(1, 12):\n",
    "            self.rules.append(eval(\"rule\" + str(i)))\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def create_control(self):\n",
    "        # call function to create robot input\n",
    "        self.create_inputs()\n",
    "        # call function to create robot output\n",
    "        self.create_outputs()\n",
    "        if self.behavior == \"avoid_obstacle\":\n",
    "            # call function to create rules\n",
    "            self.create_rules(self.front, self.left, self.right, self.output_left, self.output_right)\n",
    "            # create controller\n",
    "            self.control = skfuzzy.control.ControlSystem(self.rules)\n",
    "            \n",
    "            \n",
    "        return\n",
    "    \n",
    "    def show_fuzzy(self):         \n",
    "        if self.control is None:\n",
    "            raise Exception(\"Control not created yet!\")\n",
    "        else:\n",
    "            self.control.view()\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def create_simulator(self):\n",
    "        if self.control is None:\n",
    "            # crete controller if it doensn't exist\n",
    "            self.create_control()\n",
    "\n",
    "        # create simulator object\n",
    "        self.simulator = ctrl.ControlSystemSimulation(self.control)\n",
    "        \n",
    "        return\n",
    "            \n",
    "    def simulate(self, input_foward=None, input_left=None, input_right=None):\n",
    "        if self.simulator is None:\n",
    "            # crete simulator if it doensn't exist\n",
    "            self.create_simulator()\n",
    "        \n",
    "        # if there is no input raise exception\n",
    "        if input_foward is None or input_left is None or input_right is None:\n",
    "            raise Exception(\"Inputs can't be none\")\n",
    "        \n",
    "        # simulte the robot linear velocity based on given inputs\n",
    "        self.simulator.input['front'] = input_foward\n",
    "        self.simulator.input['left'] = input_left\n",
    "        self.simulator.input['right'] = input_right\n",
    "        \n",
    "        self.simulator.compute()\n",
    "        \n",
    "        return self.simulator.output['output_left'], self.simulator.output['output_right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Reinforcement Learning**\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controls robot actions\n",
    "\n",
    "Simple state machine that organize the robot behavior and store the informations that will be plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_machine(behavior=\"avoid_obstacle\"):\n",
    "    # first we create the robot and the walker object\n",
    "    robot = rb.Robot()\n",
    "    fuzzy = FuzzyControler(behavior=behavior)\n",
    "    \n",
    "    # instantiate the odometry calculator\n",
    "    odometry_calculator = Odometry(robot=robot)\n",
    "    \n",
    "    if behavior == \"follow_wall\":\n",
    "        raise Exception(\"Not implemented!\")\n",
    "    elif behavior == \"avoid_obstacle\":\n",
    "        while True:\n",
    "            sensors = robot.read_ultrassonic_sensors()\n",
    "            front_sensors = min(sensors[3], sensors[4])\n",
    "            left_sensors = min(sensors[0], sensors[1], sensors[2])\n",
    "            right_sensors = min(sensors[5], sensors[6], sensors[7])\n",
    "            \n",
    "            #print(front_sensors, left_sensors, right_sensors)\n",
    "            left_vel, right_vel = fuzzy.simulate(input_foward=front_sensors, input_left=left_sensors, input_right=right_sensors)\n",
    "            \n",
    "            robot.set_left_velocity(left_vel)\n",
    "            robot.set_right_velocity(right_vel)\n",
    "            \n",
    "    else:\n",
    "        raise Exception(\"Not implemented!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function - Execute the code here!\n",
    "Here is a simple signal handler implement in order to make the simulator execution last for a given time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remoteApi server.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor1 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor2 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor3 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor4 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor5 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor6 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor7 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor8 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor9 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor10 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor11 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor12 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor13 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor14 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor15 connected.\n",
      "\u001b[92m Pioneer_p3dx_ultrasonicSensor16 connected.\n",
      "\u001b[92m Vision sensor connected.\n",
      "\u001b[92m Laser connected.\n",
      "\u001b[92m Left motor connected.\n",
      "\u001b[92m Right motor connected.\n",
      "\u001b[92m Robot connected.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-f09c3d400ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpoints_kmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mstate_machine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Timed out!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-3c4bec37ba66>\u001b[0m in \u001b[0;36mstate_machine\u001b[0;34m(behavior)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbehavior\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"avoid_obstacle\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0msensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_ultrassonic_sensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mfront_sensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mleft_sensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/DUDU/Unicamp/IC/MC907/workspace/src/robot.py\u001b[0m in \u001b[0;36mread_ultrassonic_sensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimxReadProximitySensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclientID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimx_opmode_streaming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimx_return_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimxReadProximitySensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclientID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvrep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimx_opmode_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/DUDU/Unicamp/IC/MC907/workspace/lib/vrep.py\u001b[0m in \u001b[0;36msimxReadProximitySensor\u001b[0;34m(clientID, sensorHandle, operationMode)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0marr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetectedPoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0marr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0marr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetectedSurfaceNormalVector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class TimeoutException(Exception): pass\n",
    "\n",
    "@contextmanager\n",
    "def time_limit(seconds):\n",
    "    def signal_handler(signum, frame):\n",
    "        raise TimeoutException(\"Timed out!\")\n",
    "    signal.signal(signal.SIGALRM, signal_handler)\n",
    "    signal.alarm(seconds)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "\n",
    "try:\n",
    "    ground_truth = []\n",
    "    odometry = []\n",
    "    lines = []\n",
    "    corners = []\n",
    "    points_kmeans = []\n",
    "    with time_limit(90):\n",
    "        state_machine()\n",
    "except TimeoutException as e:\n",
    "    print(\"Timed out!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Results\n",
    "In order to show how the implemented code works we are going to do and discuss three experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions And Final Observations\n",
    "\n",
    "Once the project is done, it is clear that there are a number of improvements to be implemented. For the kinematic model, more sophisticated solutions, as visual odometry, visual slam, or even implement a kalman filter for odometry would give us much better results. For the mapping, even though we have obtained useful results, the K-Means suffers with to much noise, separating us from high quality results. In order to achieve better mapping results, we could implement feature extraction from images (like we were trying, but we failed), or state of art algorithms, like the Bresenham's line drawing algorithm, or the raincast, among other famous ones.\n",
    "\n",
    "Personally speaking, I believe the results were far below expectations. The learning curve for understanding the robot pipeline was longer than expected. Also, I believe a lot of time was spent on minor issues for this project, such as the implementation of the fuzzy controller. For future projects, better programming and preparation is needed to achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
