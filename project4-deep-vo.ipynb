{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Mc907/Mo651 - Mobile Robotics\n",
    "\n",
    "### Student:\n",
    "Luiz Eduardo Cartolano - RA: 183012\n",
    "\n",
    "### Instructor:\n",
    "Esther Luna Colombini\n",
    "\n",
    "### Github Link:\n",
    "[Project Repository](https://github.com/luizcartolano2/mc907-mobile-robotics)\n",
    "\n",
    "### Youtube Link:\n",
    "[Link to Video](https://youtu.be/uqNeEhWo0dA)\n",
    "\n",
    "### Subject of this Work:\n",
    "The general objective of this work is to implement a deep learning approach for solve the Visual Odometry problem.\n",
    "\n",
    "### Goals:\n",
    "1. Implement and evaluate a Deep VO strategy using images from the [AirSim](https://github.com/microsoft/AirSim) simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import math\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean wrong images\n",
    "\n",
    "While upload images obtained from the AirSim simulator were noted that some of them had failure, so, we have to clean this data to avoid noise in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|    dataset/seq1/\n",
      "|        img__0_1574447220765996000.png\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq2/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq3/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq4/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq5/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq6/\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dt in ['1','2','3','4','5','6']:\n",
    "    path = 'dataset/'+'seq'+dt+'/'\n",
    "    print(\"-------------------------------------------\")\n",
    "    print('|    '+path)\n",
    "    all_images = glob.glob(path+'images'+'/*')\n",
    "    df_poses = pd.read_csv(path+'poses.csv')[['ImageFile']].values\n",
    "    for img in df_poses:\n",
    "        if not (path+'images/'+img) in all_images:\n",
    "            print('|        '+img[0])\n",
    "    print(\"-------------------------------------------\")          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path,img_size=(1280,384)):\n",
    "    \"\"\"\n",
    "        Function to read an image from a given path.\n",
    "        \n",
    "        :param: path - image path\n",
    "        :param: img_size - image size\n",
    "        \n",
    "        :return: img - numpy array with the images pixels (converted to grayscale and normalized)\n",
    "        \n",
    "    \"\"\"\n",
    "    # read image from path\n",
    "    img = cv2.imread(path)\n",
    "    # resize image to a given size\n",
    "    img = cv2.resize(img, img_size, cv2.INTER_LINEAR)\n",
    "    # convert image to grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # normalize image pixels\n",
    "    img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_dir, img_size):\n",
    "\n",
    "    \"\"\"\n",
    "        Function to coordinate the load of all the images that are going to be used.\n",
    "        \n",
    "        :param: img_dir - path to the directory containing the images\n",
    "        :param: img_size - image size\n",
    "        \n",
    "        :return: images_set - numpy array with all images at the set\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print (\"|    Loading images from: \", img_dir)\n",
    "    # create two empty list that are going to be used for save the images\n",
    "    images= []\n",
    "    images_set =[]\n",
    "    # loop to read all the images of the directory\n",
    "    for img in glob.glob(img_dir+'/*'):\n",
    "        images.append(get_image(img,img_size))\n",
    "    # loop on the read images agrupping them two by two\n",
    "    for i in range(len(images)-1):\n",
    "        img1 = images[i]\n",
    "        img2 = images[i+1]\n",
    "        # concatenate the two images\n",
    "        img = np.concatenate([img1, img2],axis = -1)\n",
    "        images_set.append(img)\n",
    "    print(\"|    Images count : \",len(images_set))\n",
    "\n",
    "    # reshape the array of all images\n",
    "    images_set = np.reshape(images_set, (-1, 2, 384, 1280))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "    return images_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three functions are used to the Kitti Dataset poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRotationMatrix(R):\n",
    "    \"\"\" \n",
    "        Checks if a matrix is a valid rotation matrix referred from \n",
    "        https://www.learnopencv.com/rotation-matrix-to-euler-angles/\n",
    "        \n",
    "        :param: R - rotation matrix\n",
    "        \n",
    "        :return: True or False\n",
    "        \n",
    "    \"\"\"\n",
    "    # calc the transpose\n",
    "    Rt = np.transpose(R)\n",
    "\n",
    "    # check identity\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    \n",
    "    return n < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationMatrixToEulerAngles(R):\n",
    "    \"\"\" \n",
    "        Calculates rotation matrix to euler angles\n",
    "        referred from https://www.learnopencv.com/rotation-matrix-to-euler-angles\n",
    "        \n",
    "        :param: R - rotation matrix\n",
    "        \n",
    "        :return: rotation matrix for Euler angles\n",
    "    \"\"\"\n",
    "    assert(isRotationMatrix(R))\n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrices(all_poses):\n",
    "    \"\"\"\n",
    "        Function to extract matrices from poses\n",
    "        \n",
    "        :param: all_poses - list with all poses from the sequence\n",
    "        \n",
    "        :return: all_matrices - list with all matrices obtained from the poses\n",
    "    \"\"\"\n",
    "    all_matrices = []\n",
    "    for i in range(len(all_poses)):\n",
    "        #print(\"I: \",i)\n",
    "        j = all_poses[i]\n",
    "        #print(\"J:   \",j)\n",
    "        p = np.array([j[3], j[7], j[11]])\n",
    "        #print(\"P:   \", p)\n",
    "        R = np.array([[j[0],j[1],j[2]],\n",
    "                      [j[4],j[5],j[6]],\n",
    "                      [j[8],j[9],j[10]]\n",
    "                     ])\n",
    "        #print(\"R:   \", R)\n",
    "        angles = rotationMatrixToEulerAngles(R)\n",
    "        #print(\"Angles: \",angles)\n",
    "        matrix = np.concatenate((p,angles))\n",
    "        #print(\"MATRIX: \", matrix)\n",
    "        all_matrices.append(matrix)\n",
    "    return all_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kitti_images(pose_file):\n",
    "    poses = []\n",
    "    poses_set = []\n",
    "\n",
    "    with open(pose_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            pose = np.fromstring(line, dtype=float, sep=' ')\n",
    "            poses.append(pose)\n",
    "    \n",
    "    poses = getMatrices(poses)\n",
    "    for i in range(len(poses)-1):\n",
    "        pose1 = poses[i]\n",
    "        pose2 = poses[i+1]\n",
    "        finalpose = pose2-pose1\n",
    "        poses_set.append(finalpose)\n",
    "\n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two functions are used for the poses obtained from the AirSim simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_to_euler_angles(quat_matrix):\n",
    "    # create a scipy object from the quaternion angles\n",
    "    rot_mat = R.from_quat(quat_matrix)\n",
    "    # convert the quaternion to euler (in degrees)\n",
    "    euler_mat = rot_mat.as_euler('zxy', degrees=False)\n",
    "\n",
    "    #TODO: convert from (-pi,pi) to (0,2pi) ?\n",
    "    \n",
    "    return euler_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airsim_pose(pose_file):\n",
    "    poses = []\n",
    "    poses_set = []\n",
    "    \n",
    "    df_poses = pd.read_csv(pose_file)\n",
    "    for index, row in df_poses.iterrows():\n",
    "        # get the (x,y,z) positions of the camera\n",
    "        position = np.array([row['POS_X'],row['POS_Y'],row['POS_Z']])\n",
    "        # get the quaternions angles of the camera\n",
    "        quat_matrix = np.array([row['Q_W'],row['Q_X'],row['Q_Y'], row['Q_Z']])\n",
    "        # call the func that convert the quaternions to euler angles\n",
    "        euler_matrix = quat_to_euler_angles(quat_matrix)\n",
    "        # concatenate both vectors\n",
    "        poses.append(np.concatenate((position,euler_matrix)))\n",
    "        \n",
    "    for i in range(len(poses)-1):\n",
    "        pose1 = poses[i]\n",
    "        pose2 = poses[i+1]\n",
    "        finalpose = pose2-pose1\n",
    "        poses_set.append(finalpose)\n",
    "        \n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poses(pose_file, pose_format):\n",
    "    \"\"\"\n",
    "        Function to load the image poses.\n",
    "        \n",
    "        :param: pose_file - path to the pose file\n",
    "        :param: pose_format - where the pose were obtained from (AirSim, VREP, Kitti, etc...)\n",
    "        \n",
    "        :return: pose_set - set of the poses for the sequence\n",
    "    \"\"\"\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print (\"|    Pose from: \",pose_file)\n",
    "    \n",
    "    if pose_format.lower() == 'kitti':\n",
    "        poses_set = load_kitti_images(pose_file)\n",
    "    elif pose_format.lower() == 'airsim':\n",
    "        poses_set = load_airsim_pose(pose_file)\n",
    "        \n",
    "    print(\"|        Poses count: \",len(poses_set))\n",
    "    print(\"----------------------------------------------------------------------\")    \n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "\n",
    "Function that acquire all data that will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VODataLoader(datapath,img_size=(1280,384), test=False):\n",
    "    if test:\n",
    "        sequences = ['4']\n",
    "    else:\n",
    "        sequences = ['1','2','3','5','6']\n",
    "        \n",
    "    images_set = []\n",
    "    odometry_set = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        dir_path = os.path.join(datapath,'seq'+sequence)\n",
    "        image_path = os.path.join(dir_path,'images')\n",
    "        pose_path = os.path.join(dir_path,'poses.csv')\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(\"|Load from: \", dir_path)\n",
    "        images_set.append(torch.FloatTensor(load_images(image_path,img_size)))\n",
    "        odometry_set.append(torch.FloatTensor(load_poses(pose_path, 'AirSim')))\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"|   Total Images: \", len(images_set))\n",
    "    print(\"|   Total Odometry: \", len(odometry_set))\n",
    "    print(\"---------------------------------------------------\")    \n",
    "    return images_set, odometry_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq1\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq1/images\n",
      "|    Images count :  326\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq1/poses.csv\n",
      "|        Poses count:  326\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq2\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq2/images\n",
      "|    Images count :  283\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq2/poses.csv\n",
      "|        Poses count:  283\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq3\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq3/images\n",
      "|    Images count :  497\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq3/poses.csv\n",
      "|        Poses count:  497\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq5\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq5/images\n",
      "|    Images count :  121\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq5/poses.csv\n",
      "|        Poses count:  121\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq6\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq6/images\n",
      "|    Images count :  208\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq6/poses.csv\n",
      "|        Poses count:  208\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "---------------------------------------------------\n",
      "|   Total Images:  5\n",
      "|   Total Odometry:  5\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X,y = VODataLoader(datapath='dataset', test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting lists containing tensors to tensors as per the batchsize (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [item for x in X for item in x]\n",
    "Y_train = [item for a in y for item in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Details of X :\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "1435\n",
      "torch.Size([2, 384, 1280])\n",
      "---------------------------------\n",
      "Details of y :\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "1435\n",
      "torch.Size([6])\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------\")\n",
    "print(\"Details of X :\")\n",
    "print(type(X_train)) \n",
    "print(type(X_train[0]))\n",
    "print(len(X_train)) \n",
    "print(X_train[0].size())\n",
    "print(\"---------------------------------\")\n",
    "print(\"Details of y :\")\n",
    "print(type(Y_train))\n",
    "print(type(Y_train[0]))\n",
    "print(len(Y_train))\n",
    "print(Y_train[0].size())\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stack = torch.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_stack = torch.stack(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = X_stack.view(205,7,2,384,1280)\n",
    "y_batch = y_stack.view(205,7,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of X :\n",
      "torch.Size([205, 7, 2, 384, 1280])\n",
      "Details of y :\n",
      "torch.Size([205, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "print(\"Details of X :\")\n",
    "print(X_batch.size())\n",
    "print(\"Details of y :\")\n",
    "print(y_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
