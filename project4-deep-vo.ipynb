{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Mc907/Mo651 - Mobile Robotics\n",
    "\n",
    "### Student:\n",
    "Luiz Eduardo Cartolano - RA: 183012\n",
    "\n",
    "### Instructor:\n",
    "Esther Luna Colombini\n",
    "\n",
    "### Github Link:\n",
    "[Project Repository](https://github.com/luizcartolano2/mc907-mobile-robotics)\n",
    "\n",
    "### Youtube Link:\n",
    "[Link to Video](https://youtu.be/uqNeEhWo0dA)\n",
    "\n",
    "### Subject of this Work:\n",
    "The general objective of this work is to implement a deep learning approach for solve the Visual Odometry problem.\n",
    "\n",
    "### Goals:\n",
    "1. Implement and evaluate a Deep VO strategy using images from the [AirSim](https://github.com/microsoft/AirSim) simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean wrong images\n",
    "\n",
    "While upload images obtained from the AirSim simulator were noted that some of them had failure, so, we have to clean this data to avoid noise in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|    dataset/seq1/\n",
      "|        img__0_1574447220765996000.png\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq2/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq3/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq4/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq5/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq6/\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dt in ['1','2','3','4','5','6']:\n",
    "    path = 'dataset/'+'seq'+dt+'/'\n",
    "    print(\"-------------------------------------------\")\n",
    "    print('|    '+path)\n",
    "    all_images = glob.glob(path+'images'+'/*')\n",
    "    df_poses = pd.read_csv(path+'poses.csv')[['ImageFile']].values\n",
    "    for img in df_poses:\n",
    "        if not (path+'images/'+img) in all_images:\n",
    "            print('|        '+img[0])\n",
    "    print(\"-------------------------------------------\")          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path,img_size=(1280,384)):\n",
    "    \"\"\"\n",
    "        Function to read an image from a given path.\n",
    "        \n",
    "        :param: path - image path\n",
    "        :param: img_size - image size\n",
    "        \n",
    "        :return: img - numpy array with the images pixels (converted to grayscale and normalized)\n",
    "        \n",
    "    \"\"\"\n",
    "    # read image from path\n",
    "    img = cv2.imread(path)\n",
    "    # resize image to a given size\n",
    "    img = cv2.resize(img, img_size, cv2.INTER_LINEAR)\n",
    "    # convert image to grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # normalize image pixels\n",
    "    img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_dir, img_size):\n",
    "    \"\"\"\n",
    "        Function to coordinate the load of all the images that are going to be used.\n",
    "        \n",
    "        :param: img_dir - path to the directory containing the images\n",
    "        :param: img_size - image size\n",
    "        \n",
    "        :return: images_set - numpy array with all images at the set\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"-----------------------------------\")\n",
    "    print (\"|    Loading images from: \", img_dir)\n",
    "    # create two empty list that are going to be used for save the images\n",
    "    images= []\n",
    "    images_set =[]\n",
    "    # loop to read all the images of the directory\n",
    "    for img in glob.glob(img_dir+'/*'):\n",
    "        images.append(get_image(img,img_size))\n",
    "    # loop on the read images agrupping them two by two\n",
    "    for i in range(len(images)-1):\n",
    "        img1 = images[i]\n",
    "        img2 = images[i+1]\n",
    "        # concatenate the two images\n",
    "        img = np.concatenate([img1, img2],axis = -1)\n",
    "        images_set.append(img)\n",
    "    print(\"|    Images count : \",len(images_set))\n",
    "    print(\"-----------------------------------\")    \n",
    "    \n",
    "    # reshape the array of all images\n",
    "    images_set = np.reshape(images_set, (-1, 6, 384, 1280))\n",
    "\n",
    "\n",
    "    return images_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRotationMatrix(R):\n",
    "    \"\"\" Checks if a matrix is a valid rotation matrix\n",
    "        referred from https://www.learnopencv.com/rotation-matrix-to-euler-angles/\n",
    "    \"\"\"\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationMatrixToEulerAngles(R):\n",
    "    \"\"\" calculates rotation matrix to euler angles\n",
    "        referred from https://www.learnopencv.com/rotation-matrix-to-euler-angles\n",
    "    \"\"\"\n",
    "    assert(isRotationMatrix(R))\n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrices(all_poses):\n",
    "    all_matrices = []\n",
    "    for i in range(len(all_poses)):\n",
    "        #print(\"I: \",i)\n",
    "        j = all_poses[i]\n",
    "        #print(\"J:   \",j)\n",
    "        p = np.array([j[3], j[7], j[11]])\n",
    "        #print(\"P:   \", p)\n",
    "        R = np.array([[j[0],j[1],j[2]],\n",
    "                [j[4],j[5],j[6]],\n",
    "                [j[8],j[9],j[10]]])\n",
    "        #print(\"R:   \", R)\n",
    "        angles = rotationMatrixToEulerAngles(R)\n",
    "        #print(\"Angles: \",angles)\n",
    "        matrix = np.concatenate((p,angles))\n",
    "        #print(\"MATRIX: \", matrix)\n",
    "        all_matrices.append(matrix)\n",
    "    return all_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poses(pose_file):\n",
    "    print (\"pose \",pose_file)\n",
    "    poses = []\n",
    "    poses_set = []\n",
    "    with open(pose_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            pose = np.fromstring(line, dtype=float, sep=' ')\n",
    "            poses.append(pose)\n",
    "    poses = getMatrices(poses)\n",
    "    for i in range(len(poses)-1):\n",
    "        pose1 = poses[i]\n",
    "        pose2 = poses[i+1]\n",
    "        finalpose = pose2-pose1\n",
    "        poses_set.append(finalpose)\n",
    "    print(\"poses count: \",len(poses_set))\n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VODataLoader(datapath,img_size= (1280,384), test=False):\n",
    "    print (datapath)\n",
    "    poses_path = os.path.join(datapath,'data_odometry_gray\\\\dataset\\\\poses')\n",
    "    img_path = os.path.join(datapath,'data_odometry_gray\\\\dataset\\\\sequences')\n",
    "    if test:\n",
    "        sequences = ['03']  #Kindly use this sequence only for testing as this has mininum number of images\n",
    "    else:\n",
    "        #Uncomment below and comment the next to next line to work with larger data \n",
    "        #sequences= ['01','03','06']\n",
    "        sequences = ['03']  \n",
    "        \n",
    "    images_set = []\n",
    "    odometry_set = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        images_set.append(torch.FloatTensor(load_images(os.path.join(img_path,sequence,'image_0'),img_size)))\n",
    "        odometry_set.append(torch.FloatTensor(load_poses(os.path.join(poses_path,sequence+'.txt'))))\n",
    "    \n",
    "    return images_set, odometry_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
