{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Mc907/Mo651 - Mobile Robotics\n",
    "\n",
    "### Student:\n",
    "Luiz Eduardo Cartolano - RA: 183012\n",
    "\n",
    "### Instructor:\n",
    "Esther Luna Colombini\n",
    "\n",
    "### Github Link:\n",
    "[Project Repository](https://github.com/luizcartolano2/mc907-mobile-robotics)\n",
    "\n",
    "### Youtube Link:\n",
    "[Link to Video](https://youtu.be/uqNeEhWo0dA)\n",
    "\n",
    "### Subject of this Work:\n",
    "The general objective of this work is to implement a deep learning approach for solve the Visual Odometry problem.\n",
    "\n",
    "### Goals:\n",
    "1. Implement and evaluate a Deep VO strategy using images from the [AirSim](https://github.com/microsoft/AirSim) simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean wrong images\n",
    "\n",
    "While upload images obtained from the AirSim simulator were noted that some of them had failure, so, we have to clean this data to avoid noise in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|    dataset/seq1/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq2/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq3/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq4/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq5/\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "|    dataset/seq6/\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dt in ['1','2','3','4','5','6']:\n",
    "    path = 'dataset/'+'seq'+dt+'/'\n",
    "    print(\"-------------------------------------------\")\n",
    "    print('|    '+path)\n",
    "    all_images = glob.glob(path+'images'+'/*')\n",
    "    df_poses = pd.read_csv(path+'poses.csv')[['ImageFile']].values\n",
    "    for img in df_poses:\n",
    "        if not (path+'images/'+img) in all_images:\n",
    "            print('|        '+img[0])\n",
    "    print(\"-------------------------------------------\")          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rgb_mean(image_sequence):\n",
    "    '''\n",
    "        Compute the mean over each channel separately over a set of images.\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_sequence  :   np.ndarray\n",
    "                        Array of shape ``(N, h, w, c)`` or ``(h, w, c)``\n",
    "    '''\n",
    "    if image_sequence.ndim == 4:\n",
    "        _, h, w, c = image_sequence.shape\n",
    "    if image_sequence.ndim == 3:\n",
    "        h, w, c = image_sequence.shape\n",
    "    # compute mean separately for each channel\n",
    "    # somehow this expression is buggy, so we must do it manually\n",
    "    # mode = image_sequence.mean((0, 1, 2))\n",
    "    mean_r = image_sequence[..., 0].mean()\n",
    "    mean_g = image_sequence[..., 1].mean()\n",
    "    mean_b = image_sequence[..., 2].mean()\n",
    "    mean = np.array([mean_r, mean_g, mean_b])\n",
    "    return mean\n",
    "\n",
    "def mean_normalize(images_vector):\n",
    "    '''\n",
    "        Normalize data to the range -1 to 1\n",
    "    '''\n",
    "    out_images = []\n",
    "    \n",
    "    N = len(images_vector)\n",
    "    \n",
    "    print('|    Mean-normalizing ...')\n",
    "\n",
    "    mean_accumlator = np.zeros((3,), dtype=np.float32)\n",
    "\n",
    "    for idx in range(N):\n",
    "        img = images_vector[idx]\n",
    "        mean_accumlator += compute_rgb_mean(img)\n",
    "\n",
    "    mean_accumlator /= N\n",
    "    print(f'|    Mean: {mean_accumlator}')\n",
    "    \n",
    "    for idx in range(N):\n",
    "        img = images_vector[idx]\n",
    "        out_images.append(img - mean_accumlator)\n",
    "    \n",
    "    print('|    Done')\n",
    "    \n",
    "    return out_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path,img_size=(256,144)):\n",
    "    \"\"\"\n",
    "        Function to read an image from a given path.\n",
    "        \n",
    "        :param: path - image path\n",
    "        :param: img_size - image size\n",
    "        \n",
    "        :return: img - numpy array with the images pixels (converted to grayscale and normalized)\n",
    "        \n",
    "    \"\"\"\n",
    "    # read image from path\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    # normalize image pixels\n",
    "    img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_dir, img_size=(256,144)):\n",
    "\n",
    "    \"\"\"\n",
    "        Function to coordinate the load of all the images that are going to be used.\n",
    "        \n",
    "        :param: img_dir - path to the directory containing the images\n",
    "        :param: img_size - image size\n",
    "        \n",
    "        :return: images_set - numpy array with all images at the set\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print (\"|    Loading images from: \", img_dir)\n",
    "    \n",
    "    # loop to read all the images of the directory\n",
    "    images = [get_image(img,img_size) for img in glob.glob(img_dir+'/*')]\n",
    "    \n",
    "    # normalize images\n",
    "    images = mean_normalize(images)\n",
    "    \n",
    "    #resemble images as RGB\n",
    "    images = [img[:, :, (2, 1, 0)] for img in images]\n",
    "    \n",
    "    #Transpose the image that channels num. as first dimension\n",
    "    images = [np.transpose(img,(2,0,1)) for img in images]\n",
    "    images = [torch.from_numpy(img) for img in images]\n",
    "    \n",
    "    #stack per 2 images\n",
    "    images = [np.concatenate((images[k],images[k+1]),axis = 0) for k in range(len(images)-1)]\n",
    "        \n",
    "    print(\"|    Images count : \",len(images))\n",
    "\n",
    "    # reshape the array of all images\n",
    "    images_set = np.stack(images,axis=0)\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "    return images_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three functions are used to the Kitti Dataset poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRotationMatrix(R):\n",
    "    \"\"\" \n",
    "        Checks if a matrix is a valid rotation matrix referred from \n",
    "        https://www.learnopencv.com/rotation-matrix-to-euler-angles/\n",
    "        \n",
    "        :param: R - rotation matrix\n",
    "        \n",
    "        :return: True or False\n",
    "        \n",
    "    \"\"\"\n",
    "    # calc the transpose\n",
    "    Rt = np.transpose(R)\n",
    "\n",
    "    # check identity\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    \n",
    "    return n < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationMatrixToEulerAngles(R):\n",
    "    \"\"\" \n",
    "        Calculates rotation matrix to euler angles\n",
    "        referred from https://www.learnopencv.com/rotation-matrix-to-euler-angles\n",
    "        \n",
    "        :param: R - rotation matrix\n",
    "        \n",
    "        :return: rotation matrix for Euler angles\n",
    "    \"\"\"\n",
    "    assert(isRotationMatrix(R))\n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrices(all_poses):\n",
    "    \"\"\"\n",
    "        Function to extract matrices from poses\n",
    "        \n",
    "        :param: all_poses - list with all poses from the sequence\n",
    "        \n",
    "        :return: all_matrices - list with all matrices obtained from the poses\n",
    "    \"\"\"\n",
    "    all_matrices = []\n",
    "    for i in range(len(all_poses)):\n",
    "        #print(\"I: \",i)\n",
    "        j = all_poses[i]\n",
    "        #print(\"J:   \",j)\n",
    "        p = np.array([j[3], j[7], j[11]])\n",
    "        #print(\"P:   \", p)\n",
    "        R = np.array([[j[0],j[1],j[2]],\n",
    "                      [j[4],j[5],j[6]],\n",
    "                      [j[8],j[9],j[10]]\n",
    "                     ])\n",
    "        #print(\"R:   \", R)\n",
    "        angles = rotationMatrixToEulerAngles(R)\n",
    "        #print(\"Angles: \",angles)\n",
    "        matrix = np.concatenate((p,angles))\n",
    "        #print(\"MATRIX: \", matrix)\n",
    "        all_matrices.append(matrix)\n",
    "    return all_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kitti_images(pose_file):\n",
    "    poses = []\n",
    "    poses_set = []\n",
    "\n",
    "    with open(pose_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            pose = np.fromstring(line, dtype=float, sep=' ')\n",
    "            poses.append(pose)\n",
    "    \n",
    "    poses = getMatrices(poses)\n",
    "    pose1 = poses[0]\n",
    "    for i in range(len(poses)-1):\n",
    "        pose2 = poses[i+1]\n",
    "        finalpose = np.zeros(pose1)\n",
    "        poses_set.append(finalpose)\n",
    "\n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three functions are used for the poses obtained from the AirSim simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pi_to_poses(pose):\n",
    "    '''Add Pi to every pose angle.'''\n",
    "    pose += np.pi\n",
    "    \n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_to_euler_angles(quat_matrix):\n",
    "    # create a scipy object from the quaternion angles\n",
    "    rot_mat = R.from_quat(quat_matrix)\n",
    "    # convert the quaternion to euler (in degrees)\n",
    "    euler_mat = rot_mat.as_euler('yxz', degrees=False)\n",
    "    # convert from (-pi,pi) to (0,2pi)\n",
    "    euler_convert = add_pi_to_poses(euler_mat)\n",
    "    \n",
    "    return euler_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airsim_pose(pose_file):\n",
    "    \n",
    "    poses = []\n",
    "    poses_set = []\n",
    "    \n",
    "    df_poses = pd.read_csv(pose_file)\n",
    "    for index, row in df_poses.iterrows():\n",
    "        # get the (x,y,z) positions of the camera\n",
    "        position = np.array([row['POS_X'],row['POS_Y'],row['POS_Z']])\n",
    "        # get the quaternions angles of the camera\n",
    "        quat_matrix = np.array([row['Q_X'],row['Q_Y'], row['Q_Z'],row['Q_W']])\n",
    "        # call the func that convert the quaternions to euler angles\n",
    "        euler_matrix = quat_to_euler_angles(quat_matrix)\n",
    "        # concatenate both position(x,y,z) and euler angles\n",
    "        poses.append(np.concatenate((position,euler_matrix)))\n",
    "    \n",
    "    # make the first pose as start position\n",
    "    pose1 = poses[0]\n",
    "    for i in range(len(poses)):\n",
    "        pose2 = poses[i]\n",
    "        pose_diff = np.subtract(pose2, pose1)\n",
    "        pose_diff[4:] = np.arctan2(np.sin(pose_diff[4:]), np.cos(pose_diff[4:]))\n",
    "        \n",
    "        poses[i] = pose_diff\n",
    "    \n",
    "    # get the desloc between two poses\n",
    "    for i in range(len(poses)-1):\n",
    "        pose1 = poses[i]\n",
    "        pose2 = poses[i+1]\n",
    "\n",
    "        pose_diff = np.subtract(pose2, pose1)\n",
    "        pose_diff[4:] = np.arctan2(np.sin(pose_diff[4:]), np.cos(pose_diff[4:]))\n",
    "\n",
    "        poses_set.append(pose_diff)\n",
    "        \n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poses(pose_file, pose_format='airsim'):\n",
    "    \"\"\"\n",
    "        Function to load the image poses.\n",
    "        \n",
    "        :param: pose_file - path to the pose file\n",
    "        :param: pose_format - where the pose were obtained from (AirSim, VREP, Kitti, etc...)\n",
    "        \n",
    "        :return: pose_set - set of the poses for the sequence\n",
    "    \"\"\"\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print (\"|    Pose from: \",pose_file)\n",
    "    \n",
    "    if pose_format.lower() == 'kitti':\n",
    "        poses_set = load_kitti_images(pose_file)\n",
    "    elif pose_format.lower() == 'airsim':\n",
    "        poses_set = load_airsim_pose(pose_file)\n",
    "        \n",
    "    print(\"|        Poses count: \",len(poses_set))\n",
    "    print(\"----------------------------------------------------------------------\")    \n",
    "    return poses_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "\n",
    "Function that acquire all data that will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VODataLoader(datapath,img_size=(256,144), test=False, seq=None):\n",
    "    if seq is None:\n",
    "        if test:\n",
    "            sequences = ['1']\n",
    "        else:\n",
    "            sequences = ['1','2','4','5','6']\n",
    "    else:\n",
    "        sequences = [seq]\n",
    "        \n",
    "    images_set = []\n",
    "    odometry_set = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        dir_path = os.path.join(datapath,'seq'+sequence)\n",
    "        image_path = os.path.join(dir_path,'images')\n",
    "        pose_path = os.path.join(dir_path,'poses.csv')\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(\"|Load from: \", dir_path)\n",
    "        images_set.append(torch.FloatTensor(load_images(image_path,img_size)))\n",
    "        odometry_set.append(torch.FloatTensor(load_poses(pose_path, 'AirSim')))\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"|   Total Images: \", len(images_set))\n",
    "    print(\"|   Total Odometry: \", len(odometry_set))\n",
    "    print(\"---------------------------------------------------\")    \n",
    "    return images_set, odometry_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq1\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq1/images\n",
      "|    Mean-normalizing ...\n",
      "|    Mean: [0.3115534  0.29183614 0.27286035]\n",
      "|    Done\n",
      "|    Images count :  326\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq1/poses.csv\n",
      "|        Poses count:  326\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq2\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq2/images\n",
      "|    Mean-normalizing ...\n",
      "|    Mean: [0.2615339  0.24993458 0.2350733 ]\n",
      "|    Done\n",
      "|    Images count :  283\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq2/poses.csv\n",
      "|        Poses count:  283\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq4\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq4/images\n",
      "|    Mean-normalizing ...\n",
      "|    Mean: [0.34079915 0.32100374 0.28959265]\n",
      "|    Done\n",
      "|    Images count :  368\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq4/poses.csv\n",
      "|        Poses count:  368\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq5\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq5/images\n",
      "|    Mean-normalizing ...\n",
      "|    Mean: [0.13811225 0.20660812 0.3470334 ]\n",
      "|    Done\n",
      "|    Images count :  121\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq5/poses.csv\n",
      "|        Poses count:  121\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq6\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq6/images\n",
      "|    Mean-normalizing ...\n",
      "|    Mean: [0.59857106 0.6014284  0.56355304]\n",
      "|    Done\n",
      "|    Images count :  208\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq6/poses.csv\n",
      "|        Poses count:  208\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "---------------------------------------------------\n",
      "|   Total Images:  5\n",
      "|   Total Odometry:  5\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X,y = VODataLoader(datapath='dataset', test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting lists containing tensors to tensors as per the batchsize (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [item for x in X for item in x]\n",
    "Y_train = [item for a in y for item in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Details of X :\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "1306\n",
      "torch.Size([6, 144, 256])\n",
      "---------------------------------\n",
      "Details of y :\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "1306\n",
      "torch.Size([6])\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------\")\n",
    "print(\"Details of X :\")\n",
    "print(type(X_train)) \n",
    "print(type(X_train[0]))\n",
    "print(len(X_train)) \n",
    "print(X_train[0].size())\n",
    "print(\"---------------------------------\")\n",
    "print(\"Details of y :\")\n",
    "print(type(Y_train))\n",
    "print(type(Y_train[0]))\n",
    "print(len(Y_train))\n",
    "print(Y_train[0].size())\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stack = torch.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_stack = torch.stack(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = X_stack.view(-1,1,6,144,256)\n",
    "y_batch = y_stack.view(-1,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of X :\n",
      "torch.Size([1306, 1, 6, 144, 256])\n",
      "Details of y :\n",
      "torch.Size([1306, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(\"Details of X :\")\n",
    "print(X_batch.size())\n",
    "print(\"Details of y :\")\n",
    "print(y_batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = .2\n",
    "dataset_size = len(X_batch)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch_train = X_batch[split:]\n",
    "y_batch_train = y_batch[split:]\n",
    "X_batch_validation = X_batch[:split]\n",
    "y_batch_validation = y_batch[:split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining DeepVO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepVONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepVONet, self).__init__()\n",
    "        # CNN\n",
    "        # convolutional layer 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), #6 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d (64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2), \n",
    "        )\n",
    "        # convolutional layer 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d (128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 3_1        \n",
    "        self.conv3_1 = nn.Sequential(\n",
    "            nn.Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 4_1\n",
    "        self.conv4_1 = nn.Sequential(\n",
    "            nn.Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 5\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d (512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 5_1\n",
    "        self.conv5_1 = nn.Sequential(\n",
    "            nn.Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        # convolutional layer 6\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d (512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        # RNN\n",
    "        self.lstm1 = nn.LSTMCell(2*6*1024, 100)\n",
    "        self.lstm2 = nn.LSTMCell(100, 100)\n",
    "        self.fc = nn.Linear(in_features=100, out_features=6)\n",
    "\n",
    "        self.reset_hidden_states()\n",
    "\n",
    "    def reset_hidden_states(self, size=1, zero=True):\n",
    "        if zero == True:\n",
    "            self.hx1 = Variable(torch.zeros(size, 100))\n",
    "            self.cx1 = Variable(torch.zeros(size, 100))\n",
    "            self.hx2 = Variable(torch.zeros(size, 100))\n",
    "            self.cx2 = Variable(torch.zeros(size, 100))\n",
    "        else:\n",
    "            self.hx1 = Variable(self.hx1.data)\n",
    "            self.cx1 = Variable(self.cx1.data)\n",
    "            self.hx2 = Variable(self.hx2.data)\n",
    "            self.cx2 = Variable(self.cx2.data)\n",
    "\n",
    "        if next(self.parameters()).is_cuda == True:\n",
    "            self.hx1 = self.hx1.cuda()\n",
    "            self.cx1 = self.cx1.cuda()\n",
    "            self.hx2 = self.hx2.cuda()\n",
    "            self.cx2 = self.cx2.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        x = x.view(x.size(0), 2 * 6 * 1024)\n",
    "        \n",
    "        self.hx1, self.cx1 = self.lstm1(x, (self.hx1, self.cx1))\n",
    "        x = self.hx1\n",
    "        self.hx2, self.cx2 = self.lstm2(x, (self.hx2, self.cx2))\n",
    "        x = self.hx2\n",
    "        #print(x.size())\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepVONet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv3_1): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv4_1): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv5_1): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (lstm1): LSTMCell(12288, 100)\n",
      "  (lstm2): LSTMCell(100, 100)\n",
      "  (fc): Linear(in_features=100, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "model = DeepVONet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss and optimizer to be used \n",
    "criterion = torch.nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5, weight_decay=0.5)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the pretrained weight of FlowNet ( CNN part )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained = torch.load('flownets_EPE1.951.pth.tar',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.0.weight', 'conv1.1.weight', 'conv1.1.bias', 'conv1.1.running_mean', 'conv1.1.running_var', 'conv1.1.num_batches_tracked', 'conv2.0.weight', 'conv2.1.weight', 'conv2.1.bias', 'conv2.1.running_mean', 'conv2.1.running_var', 'conv2.1.num_batches_tracked', 'conv3.0.weight', 'conv3.1.weight', 'conv3.1.bias', 'conv3.1.running_mean', 'conv3.1.running_var', 'conv3.1.num_batches_tracked', 'conv3_1.0.weight', 'conv3_1.1.weight', 'conv3_1.1.bias', 'conv3_1.1.running_mean', 'conv3_1.1.running_var', 'conv3_1.1.num_batches_tracked', 'conv4.0.weight', 'conv4.1.weight', 'conv4.1.bias', 'conv4.1.running_mean', 'conv4.1.running_var', 'conv4.1.num_batches_tracked', 'conv4_1.0.weight', 'conv4_1.1.weight', 'conv4_1.1.bias', 'conv4_1.1.running_mean', 'conv4_1.1.running_var', 'conv4_1.1.num_batches_tracked', 'conv5.0.weight', 'conv5.1.weight', 'conv5.1.bias', 'conv5.1.running_mean', 'conv5.1.running_var', 'conv5.1.num_batches_tracked', 'conv5_1.0.weight', 'conv5_1.1.weight', 'conv5_1.1.bias', 'conv5_1.1.running_mean', 'conv5_1.1.running_var', 'conv5_1.1.num_batches_tracked', 'conv6.0.weight', 'conv6.1.weight', 'conv6.1.bias', 'conv6.1.running_mean', 'conv6.1.running_var', 'conv6.1.num_batches_tracked', 'lstm1.weight_ih', 'lstm1.weight_hh', 'lstm1.bias_ih', 'lstm1.bias_hh', 'lstm2.weight_ih', 'lstm2.weight_hh', 'lstm2.bias_ih', 'lstm2.bias_hh', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dict['conv1.0.weight'] = pre_trained['state_dict']['conv1.0.weight']\n",
    "update_dict['conv2.0.weight'] = pre_trained['state_dict']['conv2.0.weight']\n",
    "update_dict['conv3.0.weight'] = pre_trained['state_dict']['conv3.0.weight']\n",
    "update_dict['conv4.0.weight'] = pre_trained['state_dict']['conv4.0.weight']\n",
    "update_dict['conv4_1.0.weight'] = pre_trained['state_dict']['conv4_1.0.weight']\n",
    "update_dict['conv5.0.weight'] = pre_trained['state_dict']['conv5.0.weight']\n",
    "update_dict['conv5_1.0.weight'] = pre_trained['state_dict']['conv5_1.0.weight']\n",
    "update_dict['conv6.0.weight'] = pre_trained['state_dict']['conv6.0.weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(update_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(model, train_num, X, y, epoch_num=25):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        print(\"Epoch : \", epoch+1)\n",
    "        for i in range(train_num):\n",
    "            print(\"    Train num :\", i+1)\n",
    "            inputs = X[i]\n",
    "            print(\"        Input Size: {}\".format(inputs.size()))\n",
    "            labels = y[i]\n",
    "            print(\"        Labels: \",labels)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            model.reset_hidden_states()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            print(\"        Outputs: \",outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        print('    Epoch : %d Loss: %.3f' %(epoch+1, running_loss/train_num))\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "    print (\"Time taken in Training {0}\".format((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model_v2(model, X_train, y_train, X_validate, y_validate, num_epochs):\n",
    "    # start model train mode\n",
    "    train_ep_loss = []\n",
    "    valid_ep_loss = []\n",
    "    \n",
    "    for ep in range(num_epochs):\n",
    "        st_t = time.time()\n",
    "        print('='*50)\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        \n",
    "        loss_mean = 0\n",
    "        t_loss_list = []\n",
    "        \n",
    "        for i in range(X_train.size(0)):\n",
    "            # get the images inputs\n",
    "            inputs = X_train[i]\n",
    "            # get the original poses\n",
    "            labels = y_train[i]\n",
    "            # zero optimizer\n",
    "            optimizer.zero_grad()\n",
    "            model.reset_hidden_states()\n",
    "            \n",
    "            # predict outputs\n",
    "            outputs = model(inputs)\n",
    "            # get mse loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            ls = loss.item()\n",
    "            loss.backward()\n",
    "            # set next optimizer step\n",
    "            optimizer.step()\n",
    "            # append loss\n",
    "            t_loss_list.append(float(ls))\n",
    "            # update loss\n",
    "            loss_mean += float(ls)\n",
    "        \n",
    "        print('Train take {:.1f} sec'.format(time.time()-st_t))\n",
    "        loss_mean /= (X_train.size(0))\n",
    "        train_ep_loss.append(loss_mean)\n",
    "        \n",
    "        # Validation\n",
    "        st_t = time.time()\n",
    "        model.eval()\n",
    "        loss_mean_valid = 0\n",
    "        v_loss_list = []\n",
    "        \n",
    "        for i in range(X_validate.size(0)):\n",
    "            # get the images inputs\n",
    "            inputs = X_validate[i]\n",
    "            # get the original poses\n",
    "            labels = y_validate[i]\n",
    "            # predict outputs\n",
    "            outputs = model(inputs)\n",
    "            # get mse loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            ls = loss.item()\n",
    "            # update loss values\n",
    "            v_loss_list.append(float(ls))\n",
    "            loss_mean_valid += float(ls)\n",
    "        \n",
    "        print('Valid take {:.1f} sec'.format(time.time()-st_t))\n",
    "        loss_mean_valid /= X_validate.size(0)\n",
    "        valid_ep_loss.append(loss_mean_valid)\n",
    "        \n",
    "        print('Epoch {}\\ntrain loss mean: {}, std: {:.2f}\\nvalid loss mean: {}, std: {:.2f}\\n'.format(ep+1, loss_mean, np.std(t_loss_list), loss_mean_valid, np.std(v_loss_list)))\n",
    "        torch.save(model.state_dict(), 'model/deepvo-dropout.pt')\n",
    "        \n",
    "    return train_ep_loss, valid_ep_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Train take 599.4 sec\n",
      "Valid take 20.9 sec\n",
      "Epoch 1\n",
      "train loss mean: 0.6180626001083832, std: 1.42\n",
      "valid loss mean: 0.5603255296903894, std: 0.83\n",
      "\n",
      "==================================================\n",
      "Train take 511.4 sec\n",
      "Valid take 40.8 sec\n",
      "Epoch 2\n",
      "train loss mean: 0.598712723076641, std: 1.37\n",
      "valid loss mean: 0.565218817785211, std: 0.83\n",
      "\n",
      "==================================================\n",
      "Train take 584.7 sec\n",
      "Valid take 23.1 sec\n",
      "Epoch 3\n",
      "train loss mean: 0.5743121936756329, std: 1.31\n",
      "valid loss mean: 0.6146546840896094, std: 0.83\n",
      "\n",
      "==================================================\n",
      "Train take 606.9 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 4\n",
      "train loss mean: 0.558118683387443, std: 1.26\n",
      "valid loss mean: 0.7321459979275634, std: 0.80\n",
      "\n",
      "==================================================\n",
      "Train take 417.1 sec\n",
      "Valid take 20.5 sec\n",
      "Epoch 5\n",
      "train loss mean: 0.5525334305918116, std: 1.24\n",
      "valid loss mean: 0.6767796361925958, std: 0.79\n",
      "\n",
      "==================================================\n",
      "Train take 416.0 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 6\n",
      "train loss mean: 0.5422969933385898, std: 1.21\n",
      "valid loss mean: 0.6300672390194917, std: 0.83\n",
      "\n",
      "==================================================\n",
      "Train take 423.0 sec\n",
      "Valid take 20.6 sec\n",
      "Epoch 7\n",
      "train loss mean: 0.5382171314928801, std: 1.19\n",
      "valid loss mean: 0.7848013078230094, std: 0.80\n",
      "\n",
      "==================================================\n",
      "Train take 416.3 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 8\n",
      "train loss mean: 0.5289170128696612, std: 1.17\n",
      "valid loss mean: 0.569772297002632, std: 0.87\n",
      "\n",
      "==================================================\n",
      "Train take 411.4 sec\n",
      "Valid take 20.4 sec\n",
      "Epoch 9\n",
      "train loss mean: 0.5318374060506544, std: 1.17\n",
      "valid loss mean: 0.6297359259627845, std: 1.14\n",
      "\n",
      "==================================================\n",
      "Train take 421.7 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 10\n",
      "train loss mean: 0.5259472739815926, std: 1.15\n",
      "valid loss mean: 0.5439232115159204, std: 0.88\n",
      "\n",
      "==================================================\n",
      "Train take 419.9 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 11\n",
      "train loss mean: 0.5251578733017535, std: 1.14\n",
      "valid loss mean: 0.596214682291979, std: 0.83\n",
      "\n",
      "==================================================\n",
      "Train take 418.8 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 12\n",
      "train loss mean: 0.5242706931643433, std: 1.14\n",
      "valid loss mean: 0.596847430206978, std: 0.85\n",
      "\n",
      "==================================================\n",
      "Train take 412.5 sec\n",
      "Valid take 20.2 sec\n",
      "Epoch 13\n",
      "train loss mean: 0.5278615709686368, std: 1.14\n",
      "valid loss mean: 0.6113070844247994, std: 0.89\n",
      "\n",
      "==================================================\n",
      "Train take 420.6 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 14\n",
      "train loss mean: 0.5272562433758853, std: 1.14\n",
      "valid loss mean: 0.56901806889109, std: 1.05\n",
      "\n",
      "==================================================\n",
      "Train take 416.0 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 15\n",
      "train loss mean: 0.5231671586007762, std: 1.12\n",
      "valid loss mean: 0.5696616361909671, std: 1.06\n",
      "\n",
      "==================================================\n",
      "Train take 421.3 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 16\n",
      "train loss mean: 0.5234047363686005, std: 1.12\n",
      "valid loss mean: 0.5660568655921696, std: 1.01\n",
      "\n",
      "==================================================\n",
      "Train take 414.1 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 17\n",
      "train loss mean: 0.529169105719658, std: 1.12\n",
      "valid loss mean: 0.5647213093836532, std: 1.02\n",
      "\n",
      "==================================================\n",
      "Train take 418.7 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 18\n",
      "train loss mean: 0.5213947622533264, std: 1.12\n",
      "valid loss mean: 0.5628103055523787, std: 1.02\n",
      "\n",
      "==================================================\n",
      "Train take 422.7 sec\n",
      "Valid take 20.0 sec\n",
      "Epoch 19\n",
      "train loss mean: 0.5259123138656158, std: 1.12\n",
      "valid loss mean: 0.7000433966817184, std: 1.23\n",
      "\n",
      "==================================================\n",
      "Train take 412.0 sec\n",
      "Valid take 21.6 sec\n",
      "Epoch 20\n",
      "train loss mean: 0.5201250052897808, std: 1.11\n",
      "valid loss mean: 0.6787606843379665, std: 1.21\n",
      "\n",
      "==================================================\n",
      "Train take 422.3 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 21\n",
      "train loss mean: 0.5266404905776174, std: 1.10\n",
      "valid loss mean: 0.7564985061160706, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 418.3 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 22\n",
      "train loss mean: 0.5164946705148317, std: 1.10\n",
      "valid loss mean: 0.8523199763006292, std: 1.32\n",
      "\n",
      "==================================================\n",
      "Train take 415.6 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 23\n",
      "train loss mean: 0.5136140595260967, std: 1.09\n",
      "valid loss mean: 0.8187190336442884, std: 1.32\n",
      "\n",
      "==================================================\n",
      "Train take 409.7 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 24\n",
      "train loss mean: 0.5151563079876471, std: 1.10\n",
      "valid loss mean: 0.8238188732572442, std: 1.32\n",
      "\n",
      "==================================================\n",
      "Train take 418.1 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 25\n",
      "train loss mean: 0.5176948478160222, std: 1.11\n",
      "valid loss mean: 0.7493209904880473, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 417.7 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 26\n",
      "train loss mean: 0.5056556621122477, std: 1.08\n",
      "valid loss mean: 0.774542438601397, std: 1.27\n",
      "\n",
      "==================================================\n",
      "Train take 417.6 sec\n",
      "Valid take 20.0 sec\n",
      "Epoch 27\n",
      "train loss mean: 0.5180371629330441, std: 1.09\n",
      "valid loss mean: 0.8017979472326079, std: 1.30\n",
      "\n",
      "==================================================\n",
      "Train take 419.5 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 28\n",
      "train loss mean: 0.5152520424128247, std: 1.09\n",
      "valid loss mean: 0.7366124058599045, std: 1.25\n",
      "\n",
      "==================================================\n",
      "Train take 418.8 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 29\n",
      "train loss mean: 0.5144569285571549, std: 1.08\n",
      "valid loss mean: 0.8098237405948597, std: 1.30\n",
      "\n",
      "==================================================\n",
      "Train take 416.3 sec\n",
      "Valid take 20.2 sec\n",
      "Epoch 30\n",
      "train loss mean: 0.508757958131253, std: 1.09\n",
      "valid loss mean: 0.7805333411877696, std: 1.29\n",
      "\n",
      "==================================================\n",
      "Train take 416.2 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 31\n",
      "train loss mean: 0.504776022566313, std: 1.07\n",
      "valid loss mean: 0.878550101207191, std: 1.33\n",
      "\n",
      "==================================================\n",
      "Train take 418.6 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 32\n",
      "train loss mean: 0.5036294209844384, std: 1.07\n",
      "valid loss mean: 0.7004585322313781, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 411.9 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 33\n",
      "train loss mean: 0.49914422975931066, std: 1.06\n",
      "valid loss mean: 0.8730995479500157, std: 1.35\n",
      "\n",
      "==================================================\n",
      "Train take 418.1 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 34\n",
      "train loss mean: 0.49681413196588886, std: 1.05\n",
      "valid loss mean: 0.8475896864130351, std: 1.31\n",
      "\n",
      "==================================================\n",
      "Train take 415.4 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 35\n",
      "train loss mean: 0.49592661894540385, std: 1.06\n",
      "valid loss mean: 0.8325441919830967, std: 1.32\n",
      "\n",
      "==================================================\n",
      "Train take 423.3 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 36\n",
      "train loss mean: 0.49336552847414633, std: 1.05\n",
      "valid loss mean: 0.8517489534342426, std: 1.31\n",
      "\n",
      "==================================================\n",
      "Train take 411.3 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 37\n",
      "train loss mean: 0.49476469015335256, std: 1.05\n",
      "valid loss mean: 0.7754990518435665, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 417.1 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 38\n",
      "train loss mean: 0.4898239893054213, std: 1.04\n",
      "valid loss mean: 0.9378016480241128, std: 1.37\n",
      "\n",
      "==================================================\n",
      "Train take 412.1 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 39\n",
      "train loss mean: 0.48197649090609884, std: 1.03\n",
      "valid loss mean: 0.9324167591244896, std: 1.36\n",
      "\n",
      "==================================================\n",
      "Train take 414.3 sec\n",
      "Valid take 18.7 sec\n",
      "Epoch 40\n",
      "train loss mean: 0.4832336378655882, std: 1.04\n",
      "valid loss mean: 0.9570477047142969, std: 1.38\n",
      "\n",
      "==================================================\n",
      "Train take 412.3 sec\n",
      "Valid take 18.6 sec\n",
      "Epoch 41\n",
      "train loss mean: 0.47826543458819315, std: 1.03\n",
      "valid loss mean: 0.8831077633404184, std: 1.32\n",
      "\n",
      "==================================================\n",
      "Train take 412.7 sec\n",
      "Valid take 20.4 sec\n",
      "Epoch 42\n",
      "train loss mean: 0.4790930612918444, std: 1.04\n",
      "valid loss mean: 0.8977155088450602, std: 1.32\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Train take 416.5 sec\n",
      "Valid take 22.8 sec\n",
      "Epoch 43\n",
      "train loss mean: 0.47219263250345217, std: 1.03\n",
      "valid loss mean: 0.8333228686289198, std: 1.27\n",
      "\n",
      "==================================================\n",
      "Train take 411.5 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 44\n",
      "train loss mean: 0.4698577847020393, std: 1.02\n",
      "valid loss mean: 0.8680780693403377, std: 1.32\n",
      "\n",
      "==================================================\n",
      "Train take 420.8 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 45\n",
      "train loss mean: 0.46817641621965217, std: 1.01\n",
      "valid loss mean: 0.6581454490850255, std: 1.15\n",
      "\n",
      "==================================================\n",
      "Train take 407.7 sec\n",
      "Valid take 20.3 sec\n",
      "Epoch 46\n",
      "train loss mean: 0.46716446728906796, std: 1.01\n",
      "valid loss mean: 0.6668959437402043, std: 1.14\n",
      "\n",
      "==================================================\n",
      "Train take 417.3 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 47\n",
      "train loss mean: 0.455375853978386, std: 1.00\n",
      "valid loss mean: 0.9453158883156676, std: 1.35\n",
      "\n",
      "==================================================\n",
      "Train take 414.6 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 48\n",
      "train loss mean: 0.46411737832609085, std: 1.01\n",
      "valid loss mean: 0.7330454726814082, std: 1.20\n",
      "\n",
      "==================================================\n",
      "Train take 417.2 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 49\n",
      "train loss mean: 0.45800081432131945, std: 1.00\n",
      "valid loss mean: 0.7997873095060445, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 411.7 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 50\n",
      "train loss mean: 0.4576975834064083, std: 1.01\n",
      "valid loss mean: 0.8743547998026184, std: 1.30\n",
      "\n",
      "==================================================\n",
      "Train take 414.1 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 51\n",
      "train loss mean: 0.4549542263858176, std: 1.00\n",
      "valid loss mean: 1.0649793384404018, std: 1.40\n",
      "\n",
      "==================================================\n",
      "Train take 421.4 sec\n",
      "Valid take 20.1 sec\n",
      "Epoch 52\n",
      "train loss mean: 0.4529780759674421, std: 0.98\n",
      "valid loss mean: 0.7973649361495543, std: 1.25\n",
      "\n",
      "==================================================\n",
      "Train take 418.3 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 53\n",
      "train loss mean: 0.4456598987957155, std: 0.99\n",
      "valid loss mean: 0.8103740763104739, std: 1.24\n",
      "\n",
      "==================================================\n",
      "Train take 428.9 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 54\n",
      "train loss mean: 0.44305583896894124, std: 0.98\n",
      "valid loss mean: 0.6595916331128371, std: 1.10\n",
      "\n",
      "==================================================\n",
      "Train take 412.3 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 55\n",
      "train loss mean: 0.44223150055377597, std: 0.98\n",
      "valid loss mean: 0.9035753891357289, std: 1.30\n",
      "\n",
      "==================================================\n",
      "Train take 418.8 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 56\n",
      "train loss mean: 0.43932681554668296, std: 0.98\n",
      "valid loss mean: 0.733569399621409, std: 1.18\n",
      "\n",
      "==================================================\n",
      "Train take 413.6 sec\n",
      "Valid take 28.6 sec\n",
      "Epoch 57\n",
      "train loss mean: 0.4441756131193761, std: 0.97\n",
      "valid loss mean: 0.5504877566934431, std: 0.94\n",
      "\n",
      "==================================================\n",
      "Train take 470.6 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 58\n",
      "train loss mean: 0.4262761963176837, std: 0.96\n",
      "valid loss mean: 0.9251377769385489, std: 1.30\n",
      "\n",
      "==================================================\n",
      "Train take 418.3 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 59\n",
      "train loss mean: 0.4335058099301989, std: 0.96\n",
      "valid loss mean: 0.996883563832933, std: 1.36\n",
      "\n",
      "==================================================\n",
      "Train take 416.1 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 60\n",
      "train loss mean: 0.4299566466520032, std: 0.95\n",
      "valid loss mean: 0.8438218910232814, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 415.5 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 61\n",
      "train loss mean: 0.42091540784901454, std: 0.96\n",
      "valid loss mean: 1.0291634851146019, std: 1.37\n",
      "\n",
      "==================================================\n",
      "Train take 415.7 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 62\n",
      "train loss mean: 0.4219473539521855, std: 0.95\n",
      "valid loss mean: 1.0800668134486082, std: 1.40\n",
      "\n",
      "==================================================\n",
      "Train take 410.8 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 63\n",
      "train loss mean: 0.4217795264643158, std: 0.95\n",
      "valid loss mean: 1.000158876109283, std: 1.36\n",
      "\n",
      "==================================================\n",
      "Train take 421.2 sec\n",
      "Valid take 20.3 sec\n",
      "Epoch 64\n",
      "train loss mean: 0.4125621963231089, std: 0.95\n",
      "valid loss mean: 0.9345666243769657, std: 1.34\n",
      "\n",
      "==================================================\n",
      "Train take 413.8 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 65\n",
      "train loss mean: 0.41381868250090426, std: 0.95\n",
      "valid loss mean: 0.7180714778016924, std: 1.19\n",
      "\n",
      "==================================================\n",
      "Train take 408.4 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 66\n",
      "train loss mean: 0.40954499853741205, std: 0.94\n",
      "valid loss mean: 0.9049664226528329, std: 1.29\n",
      "\n",
      "==================================================\n",
      "Train take 409.8 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 67\n",
      "train loss mean: 0.4053674511332399, std: 0.93\n",
      "valid loss mean: 1.0370424581170652, std: 1.39\n",
      "\n",
      "==================================================\n",
      "Train take 418.1 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 68\n",
      "train loss mean: 0.4020646251843625, std: 0.93\n",
      "valid loss mean: 0.97750600463072, std: 1.35\n",
      "\n",
      "==================================================\n",
      "Train take 417.5 sec\n",
      "Valid take 20.1 sec\n",
      "Epoch 69\n",
      "train loss mean: 0.4077082419802511, std: 0.94\n",
      "valid loss mean: 0.8191948335232406, std: 1.24\n",
      "\n",
      "==================================================\n",
      "Train take 409.1 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 70\n",
      "train loss mean: 0.3964209125004876, std: 0.93\n",
      "valid loss mean: 0.8313024663705364, std: 1.27\n",
      "\n",
      "==================================================\n",
      "Train take 409.7 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 71\n",
      "train loss mean: 0.4044768492851638, std: 0.93\n",
      "valid loss mean: 0.9528887081477377, std: 1.33\n",
      "\n",
      "==================================================\n",
      "Train take 408.6 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 72\n",
      "train loss mean: 0.39928042157255134, std: 0.93\n",
      "valid loss mean: 0.8364001930659187, std: 1.25\n",
      "\n",
      "==================================================\n",
      "Train take 482.4 sec\n",
      "Valid take 21.3 sec\n",
      "Epoch 73\n",
      "train loss mean: 0.3948170326962626, std: 0.94\n",
      "valid loss mean: 0.8464441629861735, std: 1.27\n",
      "\n",
      "==================================================\n",
      "Train take 420.9 sec\n",
      "Valid take 20.0 sec\n",
      "Epoch 74\n",
      "train loss mean: 0.39054521694030214, std: 0.93\n",
      "valid loss mean: 1.0093242428854279, std: 1.36\n",
      "\n",
      "==================================================\n",
      "Train take 416.8 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 75\n",
      "train loss mean: 0.3852752131161238, std: 0.92\n",
      "valid loss mean: 0.7719628053763703, std: 1.23\n",
      "\n",
      "==================================================\n",
      "Train take 413.1 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 76\n",
      "train loss mean: 0.38994929153025465, std: 0.92\n",
      "valid loss mean: 0.7295498378125245, std: 1.20\n",
      "\n",
      "==================================================\n",
      "Train take 419.1 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 77\n",
      "train loss mean: 0.3818115970881129, std: 0.92\n",
      "valid loss mean: 0.7829988972922622, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 416.8 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 78\n",
      "train loss mean: 0.3922484296986317, std: 0.92\n",
      "valid loss mean: 0.800121080308753, std: 1.25\n",
      "\n",
      "==================================================\n",
      "Train take 414.1 sec\n",
      "Valid take 20.2 sec\n",
      "Epoch 79\n",
      "train loss mean: 0.38029859867297855, std: 0.93\n",
      "valid loss mean: 0.9936575154663274, std: 1.35\n",
      "\n",
      "==================================================\n",
      "Train take 412.6 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 80\n",
      "train loss mean: 0.3746403134820658, std: 0.91\n",
      "valid loss mean: 0.8248124405156493, std: 1.27\n",
      "\n",
      "==================================================\n",
      "Train take 407.9 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 81\n",
      "train loss mean: 0.36883213074329757, std: 0.90\n",
      "valid loss mean: 0.758525709068524, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 417.2 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 82\n",
      "train loss mean: 0.37206756547639264, std: 0.91\n",
      "valid loss mean: 0.8596657706795696, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 413.4 sec\n",
      "Valid take 20.3 sec\n",
      "Epoch 83\n",
      "train loss mean: 0.3704774970344561, std: 0.90\n",
      "valid loss mean: 0.7477151644897873, std: 1.21\n",
      "\n",
      "==================================================\n",
      "Train take 421.1 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 84\n",
      "train loss mean: 0.36289256326377983, std: 0.90\n",
      "valid loss mean: 0.6840557809883436, std: 1.13\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train take 414.8 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 85\n",
      "train loss mean: 0.366969847520585, std: 0.91\n",
      "valid loss mean: 0.806164624033874, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 419.1 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 86\n",
      "train loss mean: 0.3705263806765445, std: 0.90\n",
      "valid loss mean: 0.7098219797846601, std: 1.16\n",
      "\n",
      "==================================================\n",
      "Train take 414.9 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 87\n",
      "train loss mean: 0.36821534098397535, std: 0.90\n",
      "valid loss mean: 0.7945858842953755, std: 1.23\n",
      "\n",
      "==================================================\n",
      "Train take 415.4 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 88\n",
      "train loss mean: 0.36195808833339094, std: 0.90\n",
      "valid loss mean: 0.7841270054330143, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 410.7 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 89\n",
      "train loss mean: 0.3532505137424913, std: 0.89\n",
      "valid loss mean: 0.7800460305007824, std: 1.23\n",
      "\n",
      "==================================================\n",
      "Train take 411.7 sec\n",
      "Valid take 18.9 sec\n",
      "Epoch 90\n",
      "train loss mean: 0.3597177931197399, std: 0.88\n",
      "valid loss mean: 0.7733106435993793, std: 1.21\n",
      "\n",
      "==================================================\n",
      "Train take 409.4 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 91\n",
      "train loss mean: 0.362785074581909, std: 0.90\n",
      "valid loss mean: 0.7729215905448543, std: 1.20\n",
      "\n",
      "==================================================\n",
      "Train take 415.1 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 92\n",
      "train loss mean: 0.3550773322323792, std: 0.89\n",
      "valid loss mean: 0.9504643106240764, std: 1.36\n",
      "\n",
      "==================================================\n",
      "Train take 419.9 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 93\n",
      "train loss mean: 0.353391593541286, std: 0.89\n",
      "valid loss mean: 0.7425524873776768, std: 1.19\n",
      "\n",
      "==================================================\n",
      "Train take 416.3 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 94\n",
      "train loss mean: 0.35515458992764276, std: 0.88\n",
      "valid loss mean: 0.7726762937488912, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 417.4 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 95\n",
      "train loss mean: 0.35715895186623436, std: 0.89\n",
      "valid loss mean: 0.8362977937563283, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 415.4 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 96\n",
      "train loss mean: 0.34758952408647453, std: 0.88\n",
      "valid loss mean: 0.7315440334208395, std: 1.19\n",
      "\n",
      "==================================================\n",
      "Train take 416.2 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 97\n",
      "train loss mean: 0.35144256938744056, std: 0.88\n",
      "valid loss mean: 0.8599546661714655, std: 1.29\n",
      "\n",
      "==================================================\n",
      "Train take 408.2 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 98\n",
      "train loss mean: 0.34745102427809604, std: 0.88\n",
      "valid loss mean: 0.6849190703739494, std: 1.15\n",
      "\n",
      "==================================================\n",
      "Train take 478.9 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 99\n",
      "train loss mean: 0.34591313521567124, std: 0.88\n",
      "valid loss mean: 0.6620880952925632, std: 1.15\n",
      "\n",
      "==================================================\n",
      "Train take 417.1 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 100\n",
      "train loss mean: 0.3387837027155284, std: 0.89\n",
      "valid loss mean: 0.791907717623673, std: 1.26\n",
      "\n",
      "==================================================\n",
      "Train take 412.3 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 101\n",
      "train loss mean: 0.3465878163000377, std: 0.88\n",
      "valid loss mean: 0.6759244085992491, std: 1.15\n",
      "\n",
      "==================================================\n",
      "Train take 416.1 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 102\n",
      "train loss mean: 0.34594453799899816, std: 0.87\n",
      "valid loss mean: 0.7070309855525607, std: 1.18\n",
      "\n",
      "==================================================\n",
      "Train take 429.1 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 103\n",
      "train loss mean: 0.34409567316317025, std: 0.88\n",
      "valid loss mean: 0.6319140033917752, std: 1.12\n",
      "\n",
      "==================================================\n",
      "Train take 414.8 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 104\n",
      "train loss mean: 0.33476223826926965, std: 0.86\n",
      "valid loss mean: 0.6660748486803181, std: 1.14\n",
      "\n",
      "==================================================\n",
      "Train take 419.0 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 105\n",
      "train loss mean: 0.34392665413463974, std: 0.88\n",
      "valid loss mean: 0.6452574376730512, std: 1.10\n",
      "\n",
      "==================================================\n",
      "Train take 417.1 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 106\n",
      "train loss mean: 0.34484868446302613, std: 0.87\n",
      "valid loss mean: 0.8058727432213638, std: 1.25\n",
      "\n",
      "==================================================\n",
      "Train take 416.6 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 107\n",
      "train loss mean: 0.34622504871383725, std: 0.87\n",
      "valid loss mean: 0.6444857226777465, std: 1.12\n",
      "\n",
      "==================================================\n",
      "Train take 413.3 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 108\n",
      "train loss mean: 0.34011996120685695, std: 0.87\n",
      "valid loss mean: 0.6235395600676708, std: 1.09\n",
      "\n",
      "==================================================\n",
      "Train take 421.5 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 109\n",
      "train loss mean: 0.3318007719762897, std: 0.87\n",
      "valid loss mean: 0.7598397861809337, std: 1.22\n",
      "\n",
      "==================================================\n",
      "Train take 416.7 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 110\n",
      "train loss mean: 0.33391270610600216, std: 0.86\n",
      "valid loss mean: 0.7070637734613998, std: 1.17\n",
      "\n",
      "==================================================\n",
      "Train take 421.1 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 111\n",
      "train loss mean: 0.3370465093547964, std: 0.87\n",
      "valid loss mean: 0.7559140296510182, std: 1.21\n",
      "\n",
      "==================================================\n",
      "Train take 414.1 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 112\n",
      "train loss mean: 0.32870663393591865, std: 0.86\n",
      "valid loss mean: 0.5988836225686003, std: 1.06\n",
      "\n",
      "==================================================\n",
      "Train take 411.6 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 113\n",
      "train loss mean: 0.32866025498632895, std: 0.86\n",
      "valid loss mean: 0.6326963473682317, std: 1.10\n",
      "\n",
      "==================================================\n",
      "Train take 418.0 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 114\n",
      "train loss mean: 0.3383853329525777, std: 0.88\n",
      "valid loss mean: 0.6079144129722283, std: 1.08\n",
      "\n",
      "==================================================\n",
      "Train take 410.1 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 115\n",
      "train loss mean: 0.32834074355210136, std: 0.85\n",
      "valid loss mean: 0.6782402166796998, std: 1.15\n",
      "\n",
      "==================================================\n",
      "Train take 412.1 sec\n",
      "Valid take 20.6 sec\n",
      "Epoch 116\n",
      "train loss mean: 0.3323963577183728, std: 0.87\n",
      "valid loss mean: 0.6571438228497388, std: 1.15\n",
      "\n",
      "==================================================\n",
      "Train take 422.9 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 117\n",
      "train loss mean: 0.3258738080362269, std: 0.86\n",
      "valid loss mean: 0.6946551607086741, std: 1.16\n",
      "\n",
      "==================================================\n",
      "Train take 410.1 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 118\n",
      "train loss mean: 0.3275744996564023, std: 0.86\n",
      "valid loss mean: 0.7868088632607939, std: 1.23\n",
      "\n",
      "==================================================\n",
      "Train take 421.0 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 119\n",
      "train loss mean: 0.3286943579253041, std: 0.86\n",
      "valid loss mean: 0.5410710609557242, std: 0.98\n",
      "\n",
      "==================================================\n",
      "Train take 412.8 sec\n",
      "Valid take 20.0 sec\n",
      "Epoch 120\n",
      "train loss mean: 0.320957164851972, std: 0.86\n",
      "valid loss mean: 0.7064628330919306, std: 1.17\n",
      "\n",
      "==================================================\n",
      "Train take 417.8 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 121\n",
      "train loss mean: 0.32503582517951773, std: 0.86\n",
      "valid loss mean: 0.5958853188020773, std: 1.06\n",
      "\n",
      "==================================================\n",
      "Train take 409.8 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 122\n",
      "train loss mean: 0.323084639628283, std: 0.86\n",
      "valid loss mean: 0.6550131770157722, std: 1.13\n",
      "\n",
      "==================================================\n",
      "Train take 416.9 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 123\n",
      "train loss mean: 0.32116009940554247, std: 0.85\n",
      "valid loss mean: 0.7022892424044596, std: 1.17\n",
      "\n",
      "==================================================\n",
      "Train take 419.6 sec\n",
      "Valid take 19.8 sec\n",
      "Epoch 124\n",
      "train loss mean: 0.3224505161052195, std: 0.85\n",
      "valid loss mean: 0.6024161142571847, std: 1.07\n",
      "\n",
      "==================================================\n",
      "Train take 421.1 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 125\n",
      "train loss mean: 0.3154733337406108, std: 0.84\n",
      "valid loss mean: 0.6468372464526116, std: 1.11\n",
      "\n",
      "==================================================\n",
      "Train take 423.5 sec\n",
      "Valid take 19.9 sec\n",
      "Epoch 126\n",
      "train loss mean: 0.3166949512329483, std: 0.86\n",
      "valid loss mean: 0.6312115470382789, std: 1.10\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train take 412.2 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 127\n",
      "train loss mean: 0.320560556912695, std: 0.85\n",
      "valid loss mean: 0.5654339917553625, std: 1.02\n",
      "\n",
      "==================================================\n",
      "Train take 417.4 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 128\n",
      "train loss mean: 0.3177212367066139, std: 0.85\n",
      "valid loss mean: 0.6302511374434007, std: 1.11\n",
      "\n",
      "==================================================\n",
      "Train take 413.6 sec\n",
      "Valid take 19.7 sec\n",
      "Epoch 129\n",
      "train loss mean: 0.3134299659052959, std: 0.83\n",
      "valid loss mean: 0.5423961617944627, std: 0.98\n",
      "\n",
      "==================================================\n",
      "Train take 417.4 sec\n",
      "Valid take 19.1 sec\n",
      "Epoch 130\n",
      "train loss mean: 0.321764082479587, std: 0.86\n",
      "valid loss mean: 0.5246639704881272, std: 0.93\n",
      "\n",
      "==================================================\n",
      "Train take 475.4 sec\n",
      "Valid take 20.6 sec\n",
      "Epoch 131\n",
      "train loss mean: 0.32093827430263017, std: 0.85\n",
      "valid loss mean: 0.563327383997554, std: 1.04\n",
      "\n",
      "==================================================\n",
      "Train take 415.6 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 132\n",
      "train loss mean: 0.31930860880401396, std: 0.84\n",
      "valid loss mean: 0.7033567674408071, std: 1.16\n",
      "\n",
      "==================================================\n",
      "Train take 413.8 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 133\n",
      "train loss mean: 0.3174430478538852, std: 0.84\n",
      "valid loss mean: 0.5183229564450025, std: 0.94\n",
      "\n",
      "==================================================\n",
      "Train take 410.1 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 134\n",
      "train loss mean: 0.3147186049988004, std: 0.84\n",
      "valid loss mean: 0.5347015388645374, std: 0.97\n",
      "\n",
      "==================================================\n",
      "Train take 419.2 sec\n",
      "Valid take 20.0 sec\n",
      "Epoch 135\n",
      "train loss mean: 0.31420986670237616, std: 0.84\n",
      "valid loss mean: 0.6914792604016504, std: 1.18\n",
      "\n",
      "==================================================\n",
      "Train take 422.3 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 136\n",
      "train loss mean: 0.3160413296783508, std: 0.83\n",
      "valid loss mean: 0.5460058499352428, std: 1.00\n",
      "\n",
      "==================================================\n",
      "Train take 414.0 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 137\n",
      "train loss mean: 0.3151554867379038, std: 0.83\n",
      "valid loss mean: 0.5716767264690635, std: 1.04\n",
      "\n",
      "==================================================\n",
      "Train take 417.5 sec\n",
      "Valid take 20.6 sec\n",
      "Epoch 138\n",
      "train loss mean: 0.3144271741167093, std: 0.84\n",
      "valid loss mean: 0.5355789300814356, std: 0.95\n",
      "\n",
      "==================================================\n",
      "Train take 415.6 sec\n",
      "Valid take 18.8 sec\n",
      "Epoch 139\n",
      "train loss mean: 0.3150629871424887, std: 0.83\n",
      "valid loss mean: 0.5858983238391806, std: 1.06\n",
      "\n",
      "==================================================\n",
      "Train take 418.0 sec\n",
      "Valid take 19.2 sec\n",
      "Epoch 140\n",
      "train loss mean: 0.3105923091301764, std: 0.83\n",
      "valid loss mean: 0.5533491242302303, std: 1.01\n",
      "\n",
      "==================================================\n",
      "Train take 420.2 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 141\n",
      "train loss mean: 0.3091362015616581, std: 0.83\n",
      "valid loss mean: 0.5804423245983162, std: 1.04\n",
      "\n",
      "==================================================\n",
      "Train take 416.5 sec\n",
      "Valid take 19.6 sec\n",
      "Epoch 142\n",
      "train loss mean: 0.3134335283718058, std: 0.84\n",
      "valid loss mean: 0.5483466524156203, std: 1.00\n",
      "\n",
      "==================================================\n",
      "Train take 421.2 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 143\n",
      "train loss mean: 0.30489302399071405, std: 0.82\n",
      "valid loss mean: 0.5703795152998233, std: 1.04\n",
      "\n",
      "==================================================\n",
      "Train take 414.8 sec\n",
      "Valid take 18.3 sec\n",
      "Epoch 144\n",
      "train loss mean: 0.30706703383014616, std: 0.83\n",
      "valid loss mean: 0.5340259899081969, std: 0.97\n",
      "\n",
      "==================================================\n",
      "Train take 474.3 sec\n",
      "Valid take 20.0 sec\n",
      "Epoch 145\n",
      "train loss mean: 0.31557682830847034, std: 0.84\n",
      "valid loss mean: 0.540331896754888, std: 1.00\n",
      "\n",
      "==================================================\n",
      "Train take 412.3 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 146\n",
      "train loss mean: 0.3092107014903246, std: 0.82\n",
      "valid loss mean: 0.5285176116031134, std: 0.94\n",
      "\n",
      "==================================================\n",
      "Train take 421.5 sec\n",
      "Valid take 19.3 sec\n",
      "Epoch 147\n",
      "train loss mean: 0.31063580605144053, std: 0.84\n",
      "valid loss mean: 0.5610948606176566, std: 1.03\n",
      "\n",
      "==================================================\n",
      "Train take 419.7 sec\n",
      "Valid take 19.5 sec\n",
      "Epoch 148\n",
      "train loss mean: 0.3146617083167479, std: 0.83\n",
      "valid loss mean: 0.5456338681073652, std: 0.99\n",
      "\n",
      "==================================================\n",
      "Train take 417.5 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 149\n",
      "train loss mean: 0.3059283511839867, std: 0.82\n",
      "valid loss mean: 0.5526523923401461, std: 1.00\n",
      "\n",
      "==================================================\n",
      "Train take 422.8 sec\n",
      "Valid take 19.4 sec\n",
      "Epoch 150\n",
      "train loss mean: 0.3039418498260798, std: 0.83\n",
      "valid loss mean: 0.5390428111128424, std: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, valid_loss = training_model_v2(model, X_batch_train, y_batch_train, X_batch_validation, y_batch_validation, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydeXhcVd34PyfJTPalTdIt3Te6t5RQllKggNCCsotUQAEF5RVxA628/JSXF19xA1wQBa2KsogoiLIqIJS1G1DovtN0TdJmT2aSzPn9ce6Ze+fOnsxkPZ/nyXNn7tx750xm7vme7y6klBgMBoNh8JLR2wMwGAwGQ+9iBIHBYDAMcowgMBgMhkGOEQQGg8EwyDGCwGAwGAY5Wb09gGQpKyuT48eP7+1hGAwGQ79i7dq1NVLK8kiv9TtBMH78eNasWdPbwzAYDIZ+hRBiT7TX0mYaEkKsEEIcFkJ8GOX1aUKIt4QQPiHEzekah8FgMBhik04fwe+BJTFePwLcBPw4jWMwGAwGQxzSJgiklK+hJvtorx+WUq4G2tM1BoPBYDDEp1/4CIQQ1wPXA4wdO7aXR2MwDA7a29upqqqira2tt4diSIKcnBxGjx6Nx+NJ+Jx+IQiklA8ADwBUVlaa4kgGQw9QVVVFYWEh48ePRwjR28MxJICUktraWqqqqpgwYULC55k8AoPBEJG2tjZKS0uNEOhHCCEoLS1NWoszgsBgMETFCIH+R1e+s7SZhoQQjwKnA2VCiCrgu4AHQEr5KyHECGANUAQEhBBfBWZIKRvSNSbDIGPfOgh0wpjje3skBkOfJp1RQ8uklCOllB4p5Wgp5W+llL+SUv7Kev2gtb9ISlliPTZCwJA6nvsmPGtSVPojtbW1zJs3j3nz5jFixAgqKiqCz/1+f0LXuOaaa9iyZUvMY+677z4efvjhVAyZU045hffeey8l1+pp+oWz2GBIGimheit4cnp7JIYuUFpaGpxUb7/9dgoKCrj55lChLqVESklGRuT17O9+97u47/OlL32p+4MdABgfgWFg0nQYfPVq29nR26MxpIjt27czY8YMrrjiCmbOnMmBAwe4/vrrqaysZObMmdxxxx3BY/UKvaOjg5KSEpYvX87cuXM56aSTOHz4MAC33XYb9957b/D45cuXs2DBAo455hjefPNNAJqbm7nkkkuYMWMGl156KZWVlQmv/FtbW/nsZz/L7NmzmT9/Pq+99hoAH3zwAccffzzz5s1jzpw57Ny5k8bGRpYuXcrcuXOZNWsWTzzxRCr/dTExGoGhd+nwwyt3wilfh9yS1F23RpsEJDRXQ9HI1F17EPI//9jAxv2ptdzOGFXEdz8xM+nzNm/ezEMPPURlZSUAd911F0OHDqWjo4PFixdz6aWXMmPGjJBz6uvrOe2007jrrrv4+te/zooVK1i+fHnYtaWUrFq1iqeffpo77riD559/np///OeMGDGCv/71r7z//vvMnz8/4bH+7Gc/Izs7mw8++IANGzZw7rnnsm3bNn75y19y880386lPfQqfz4eUkr///e+MHz+e5557LjjmnsJoBIbe5eB6eOOnsHtlaq9bs9V+3Hggtdc29CqTJk0KCgGARx99lPnz5zN//nw2bdrExo0bw87Jzc1l6dKlABx33HHs3r074rUvvvjisGNef/11Lr/8cgDmzp3LzJmJC6/XX3+dK6+8EoCZM2cyatQotm/fzsknn8ydd97JD3/4Q/bu3UtOTg5z5szh+eefZ/ny5bzxxhsUFxcn/D7dxWgEht7F36y2Hb7UXrdmm/248WBqrz0I6crKPV3k5+cHH2/bto2f/vSnrFq1ipKSEq688sqIMfRerzf4ODMzk46OyObC7OzsuMekgquuuoqTTjqJZ555hiVLlrBixQpOPfVU1qxZw7PPPsvy5ctZunQpt956a9rG4MRoBIbepb1FbVMtCKq3QMEI9bjJCIKBSkNDA4WFhRQVFXHgwAFeeOGFlL/HwoULefzxxwFl24+kcURj0aJFwaikTZs2ceDAASZPnszOnTuZPHkyX/nKV/j4xz/O+vXr2bdvHwUFBVx11VV84xvfYN26dSn/LNEwGoGhdwlqBCmuZ1OzDcYvhA//ZjSCAcz8+fOZMWMG06ZNY9y4cSxcuDDl7/HlL3+Zz3zmM8yYMSP4F81sc8455wRr/CxatIgVK1bwhS98gdmzZ+PxeHjooYfwer088sgjPProo3g8HkaNGsXtt9/Om2++yfLly8nIyMDr9fKrX/0q5Z8lGkLK/lW6p7KyUprGNAOIdQ/B01+Gc74PJ/1Xaq7pa4LvV8AZt8GqB2HqOXD+z1Nz7UHEpk2bmD59em8Po9fp6Oigo6ODnJwctm3bxtlnn822bdvIyuq76+hI350QYq2UsjLS8X33kxgGB37LNNSZQtNQreUfKJsKBcONRmDoFk1NTZx55pl0dHQgpeTXv/51nxYCXWFgfRpD/yMdPgLtKC47BgpHxo8aOroHqlbD7EtTNwbDgKGkpIS1a9f29jDSinEWG3qXoCBIoY+geguITBg6EQpHxNcI1qyAv37O1k4MhkGGEQSG3kVPvh2J1Y9JiJqtMHQCZHmVIGiujp1d3FantnVRe3sbDAMaIwgMvUt7GqKGGvZBidXJrnAEKrv4cPTj26yM2aO7UzcGg6EfYQSBoXdpb1XbVPoI/M3gLVCPC63SErH8BG1WKv+RXakbg8HQjzCCwNC76DyCVEYN+VvAa2WfFgxX21h+Ap/RCPoaixcvDksOu/fee7nhhhtinldQoBYA+/fv59JLIzv/Tz/9dOKFoN977720tNg+o3PPPZe6urpEhh6T22+/nR//+Mfdvk6qMYLA0Lukw1nc3gyePPU4GY3gqNEI+grLli3jscceC9n32GOPsWzZsoTOHzVqVLeqd7oFwbPPPktJSQqLIvYx0iYIhBArhBCHhRAfRnldCCF+JoTYLoRYL4RIvKSfYeDgT0P4qL8FvJYgyC8HkQGNh6If31UfQSAA7z8Gne1dGqYhOpdeeinPPPNMsAnN7t272b9/P4sWLQrG9c+fP5/Zs2fz97//Pez83bt3M2vWLECVgr788suZPn06F110Ea2trcHjbrjhhmAJ6+9+97uAqhi6f/9+Fi9ezOLFiwEYP348NTU1ANx9993MmjWLWbNmBUtY7969m+nTp3Pdddcxc+ZMzj777JD3iUekazY3N3PeeecFy1L/+c9/BmD58uXMmDGDOXPmhPVo6CrpzCP4PfAL4KEory8Fplh/JwD3W1vDYKI9xUXnAgHoaAWPZRrKzFLCICGNYI86P0qjkzD2r4MnvwD5ZTD5rO6Nu6/z3HI4+EFqrzliNiy9K+JLQ4cOZcGCBTz33HNccMEFPPbYY1x22WUIIcjJyeHJJ5+kqKiImpoaTjzxRM4///yovXrvv/9+8vLy2LRpE+vXrw8pI/29732PoUOH0tnZyZlnnsn69eu56aabuPvuu3nllVcoKysLudbatWv53e9+xzvvvIOUkhNOOIHTTjuNIUOGsG3bNh599FEefPBBLrvsMv76178GK4/GIto1d+7cyahRo3jmmWcAVZa6traWJ598ks2bNyOESIm5CtLbqvI14EiMQy4AHpKKt4ESIYQpGj/YSLWzWJuatEYAsXMJOvxKcBRVKD9FMiWrW62b0NfUtbEaYuI0DznNQlJKbr31VubMmcNZZ53Fvn37OHQousb32muvBSfkOXPmMGfOnOBrjz/+OPPnz+fYY49lw4YNcQvKvf7661x00UXk5+dTUFDAxRdfzMqVqoT6hAkTmDdvHhC71HWi15w9ezb/+te/+Na3vsXKlSspLi6muLiYnJwcPve5z/G3v/2NvLy8+G+QAL2ZWVwB7HU8r7L2meLxgwl/CnwER/eoKKH8UlsQeJyCYCTUV0U+VzuKR85VYadHd0FxRWLv67cEQKorp/ZFoqzc08kFF1zA1772NdatW0dLSwvHHXccAA8//DDV1dWsXbsWj8fD+PHjI5aejseuXbv48Y9/zOrVqxkyZAhXX311l66j0SWsQZWxTsY0FImpU6eybt06nn32WW677TbOPPNMvvOd77Bq1SpeeuklnnjiCX7xi1/w8ssvd+t9oJ84i4UQ1wsh1ggh1lRXV/f2cAypRJuGOruRUPbwJ+Hfyr4bjELy2jXrKR4N9XvDzwPbLDRyrtom4ycICoIEbvgtz5maR0lSUFDA4sWLufbaa0OcxPX19QwbNgyPx8Mrr7zCnj2xEwFPPfVUHnnkEQA+/PBD1q9fD6gS1vn5+RQXF3Po0KFgZzCAwsJCGhsbw661aNEinnrqKVpaWmhububJJ59k0aJF3fqc0a65f/9+8vLyuPLKK7nllltYt24dTU1N1NfXc+6553LPPffw/vvvd+u9Nb2pEewDxjiej7b2hSGlfAB4AFT10fQPzdBjdFcjCATgyE4YMl49j6QRFI9RE35bA+QUhZ6vBcGwGaosRTK5BNok1B5n7J0d8Nin4dRvwuJvJ359A8uWLeOiiy4KiSC64oor+MQnPsHs2bOprKxk2rRpMa9xww03cM011zB9+nSmT58e1Czmzp3Lsccey7Rp0xgzZkxICevrr7+eJUuWMGrUKF555ZXg/vnz53P11VezYMECAD7/+c9z7LHHJmwGArjzzjuDDmGAqqqqiNd84YUXuOWWW8jIyMDj8XD//ffT2NjIBRdcQFtbG1JK7r777oTfNyZSyrT9AeOBD6O8dh7wHCCAE4FViVzzuOOOk4YBQodfyu8Wqb+fTO/aNRoOqvNXLFXPP1qlnm990T7mgyfUvoMfhp+//WX12u43pLxntpR/uTbx9371R+rclffEPq61Xh333PLEr90H2LhxY28PwdBFIn13wBoZZV5Nm0YghHgUOB0oE0JUAd8FPJbw+RXwLHAusB1oAa5J11gMfZR2R5G3rtrZGyzbv7b1a1OTUyMoGae2dR/BcFfLRX1edpGqT5RMLkHQNBRHI9Cf02+cyoa+SdoEgZQyZuaHJaG+lK73N/QDtFkoK7frgqDesiZqM40/QtRQsWWBrIvgJ9CmoZxiZV7a9I/E31v7I9rj+Aj0cXprMPQx+oWz2DBA0SvlvKFd9xE07FdbvdoO+ggczuL8csjMhvqPws/XyWQ5RUpgtNTGn9g1vgSjhvT1+mGYqexnHQwNXfvOjCAw9B56hZw7BALtyvGbLEHTUGPoNZ0aQUYGlIyJoREI8BYqrcB5rXj4rePiRQ0FTUP9SyPIycmhtrbWCIN+hJSS2tpacnJykjrPdCgz9B56pZw7RG07fZCRm9w1tGmoo02VevBH8BGAWu3XRdAIfA3KP5CRYVcs9TVCwbD47x00DQ1MH8Ho0aOpqqrChGz3L3Jychg9enRS5xhBYOg92h0aAajJ3JOkINCmIVATuL6mntQ1JWNgS4SyV231tiaQbZ2T6ITtS9BZ7O+fGoHH42HChAm9PQxDD2BMQ4bEaG9LvY3b7/ARQNe6lDXsU0XlQE3g/hbIyFLdyZwUj1Wdytz2/7YGWxAENYIEP6c/waY6/dQ0ZBg8GEFgSIynb4Q/XZLaa+oJ0qkRJEOgU9UGGmKtWn1N6ppOR7FGdyxzl5poq7eTzLIL1TbShB2pwqj2EcRzLhtBYOjjGEFgiI+vSYVVHt6U2usGBYHWCJIMIW06DIEOKLcyS32NVneyCIW4SnQIqascgdM0pDUCv8tZvOdN+P7o8FLW/gQrp/odPoJ0O16ba2Hj0+l9D8OAwwgCQ3y2vahW67765M1DUkJLlCK0fpdGkGyXsgbLUVx+jHW9RksjiCAIouUS+OqVsxhsH4H7M1ZvVp/f7Wz2JVhrSAs82ZnaBjyReP8RePwqOz/CYEgAIwgM8dnkWGEmU6YZYPu/4SfToLkm/LUwZ3E3BYGvMbQpjZPCkcp34C4+F1EjcAkCXW66zVH7vbPdFlyJRg1B+s1DOi/C3xL7OIPBgREEhsi0HFGTd3srbH0RyqzJtiFiXcDo1FepCbM5Qgiiduxq23yyq+V6tyBostpURvARZGZB0ahQjSAQUMJD+wiiOYu1AGg96hi745hEo4bc56UDLXTajSAwJI4RBIbIPHUD3Dsbnr5JTa4nfEHtd4ZrJoIuLx1pYtKO3SyrjntXNIKsHLuWUCyNAFTkkNO8428CGbA1gswsVe7C7SNojSAItLAQmYlHDUH6NYJghnX3auEbBhdGEBgi07BfTeIfPK5MN3Mus/YnqRHoSTKS+aTdmrS7IwiKKhzRPk3RfQQARSOhydETwFlwTpNdEEMjcJiG9ISeV9q3TENa+zCCwJAEJqHMEBl/E8y4AKYuVZN1dqGK7mlI0kegcwMiTUz+FpVAlmWlwyfrLK7fp8w9mR51jWDUUATTECgB4RyHs+CcxlsQ3UcQyTSUXwa1O2KPs70HTUPBbGdjGjIkjtEIDJHxN6tJcc4nYdp5al9RRRdMQ9qhGsM0lGklfyWrETQeUGMCNVZfjKghsASBY/UeLDjnEAQxNQKnacgyH+WXqc8Yq06Sv0UVvYP0F55rT7AiqsHgwAgCQ2R8TbbJRVM0quumoUh2dB3zrzWCZJ3F7S326j+70M4sjqoR5IQKpKBG4DANeQsTixoKmobK4o+9vcWuXZR205DObTCCwJA4RhAYwgkE1MrSXa+naFTyGkFHLGdxq1qlBwVBkiUmOtttbSK7QK3w42kEgXbVOhJsH0FOiX1MdkF49dFYUUP5CQoCfVzaTUPGR2BIHiMIDOEEC7e5VtZFo6ClJr5z1EnQWRxhYtKTtq4LlKxG0NmuIn1AOXybqwEZPWooKHCssWiNwOksdvsIAgHbhBTiLLaOSUQj8LdAfk9pBK6+DAZDAqRVEAghlgghtgghtgshlkd4fZwQ4iUhxHohxH+EEMnVTjWkB23Hzo6gEUBySWWdsZzFbtNQkj6CTr+tEXgLoMkqAREpjwDsyqZakOmVfk6MqCFfA2CVhYgUPqpX+rFW4O2t1nGi50xDRiMwJEHaBIEQIhO4D1gKzACWCSFmuA77MfCQlHIOcAfw/XSNx5AEelXpjeAjgOQEgZ7cY2kEGVmqgmi0qKH3Hws3SQUCqmRDhkc9zy5QtYcgho9ACwJrtdzWoISQDl+FcB+BFhb5w5Qg0LWC/M2ASCwrur1ZfU5vQfoFQbsxDRmSJ50awQJgu5Ryp5TSDzwGXOA6ZgbwsvX4lQivG3qDoCBwm4asCJ2G/WpCTKSjWEeMqCHt2BVCTciRzCvtbfDkF+Ddh0P3B6xqoJlaEBTa+6KZhrQg0O/jbwr3g2RbpiH92bQ5aOgEdX1nkxlvgeOaMSZeneTmzU+vjyAQMJnFhi6RTkFQATgLu1RZ+5y8D1xsPb4IKBRClLovJIS4XgixRgixxnRL6gHimYYa9sGLt8EDp8a/ll7luyd5KS2NwJpIM72RV9XBidflwO10CQLnhB7NNJTl0ggiZSFr4af9JFoj0KWutXnI16j+P9qsFc1vEuhU/wNPDwgC5+RvNAJDEvS2s/hm4DQhxLvAacA+oNN9kJTyASllpZSysry8vKfHOPgIagTu1XKhMp3sfBXevh8OfhDfcRzNNNTpV6YdHeGTlRNZEOh9bpOK9j0Eo4acDt9oGoFr0o5Ul8hdb0hrBEPGW8+P2uMJ0Qii/B/05BwUBGk0DTmvbTQCQxKkM7N4HzDG8Xy0tS+IlHI/lkYghCgALpFS1mHoXYIN4AvCXysaBTtesp/XV0HZ5OjXimYa8rsik7KyowiC1tDjNQErBDRDRw05NYIY4aPOsUTSCJzlKsDWCIZqjaDOft3rrJMUTRBY4/f2gI+g3SkI0lzu2jCgSKdGsBqYIoSYIITwApcDIR0zhBBlQug+g3wbWJHG8RgSRcfRu01DYJuHJp+ltu5GL26ilWp2rpTBEgQRJq+gRuAyqbg1AqfQiuYsdieuRco5cDawh9gaQXahw9wUxRSjJ/6eMA0ZjcDQRdImCKSUHcCNwAvAJuBxKeUGIcQdQojzrcNOB7YIIbYCw4HvpWs8g5bWOmWnToZopiGAYTNUFc8ld6nn7mYtbqJpBMGVskMj6IyQUNYeRSNw+wicWdBxNQLHNd1Cw93Avq1OaR3aUa41BF+jOtcTJ/S1R01Dxkdg6BppLTonpXwWeNa17zuOx08AT6RzDIMafwvcOweW/gDmLUvivCgJZQAfuwMW36ps4xlZSQgC18QUXClbK+poUUNRfQRaEGgfgUMQxCox4RxLTI3A4SPIKbHDRIMagRU15E5Sc6Pfy5NnRSSlUxBYY870GkFgSIredhYb0knTIdWK0TlZP3sLbH8p+jmgVruePMjIDH8tM0tNaBmZUDw6viDQq3z3ROk0mYAqyhbRR9AWerxGh4oGfQRd0QgS8RFYHcy8+SpnIcQ0lEDUUFCoah9BD5iG8sqMaciQFEYQDGRaatVWOxGlhFUPwuv3xD4vUnx9JEocjV4a9sOGp8KPiVZiQvcFKBiutlGdxY6YfydujUCPV2SEJog5ca/eY0YNWT6CtjrILVG5Drklts/A584jiOMs1qYhXxob2OvJP7/UaASGpDCCYCCj+wSHlB2QsOfN6A3l9fHRzCtOnB2/Vt4Nf7naLuimidaPQGcKa+dz1PDRKBpBmI/AmsA9VoJaJDwux25EjcDlI9CmIVDmodajoUX5Mr2AiCEIXM5i2Zl8KY1ECRbCKzeCwJAURhAMZFq0INDhkloz6IStz0c/z9cUOWLITclYtbJvb4OP3gZkuAmoM4qPoOGAmhx1L4Asb/TMYufYNWGZxbrvcBSzEChzlrafd7ara7g1Av3c53AW57oEgbMon86Kjho11GKPS2sbzs9yeDM0Hoo+5mTQ75WIaUhK2Pj35AMJDAMSIwgGMkGNoCl0C7D5mejn+ZvC6wxFomSs2lZvgsMb1GPnhBgIRC8612B1F9Or96ycyLWGnKGezklLXzfDlVkczT+g8eSqsQSjeXJDX8/ICLXlOzWCnBIlGPREHtRComgzEG4agtDv4dHL4eX/jT3mRAlpnxlHI9j7Djz+Gdj9emre29CvMYKgL9JcCx/+tfvXCfoIXBpB4SjlMHaGG9Zss9tQ6mSpeGhB8OFfVRN453tB6GTd0RpqG288AIUj7efxfATO8YNtgtI+giyvcjjHG3dWrhqLc6XuRnc7k1I5i90agc8VXpuVEyNqyGUacn4OKZWJrClFGkF7s/p82QXh/283+rehS3EbBjVGEPRF3nsYnrg2fi/ceOibXU88ejvnk2qi2GHV+2tvgxVL4IVb1fNkTEMAHziElnMlqifxYIVOx6TesN+OzQcraihS+Gg0QaATyhwR0NkF8QVBmEYQ4XhdeM7XqMxoQR9BCbTW23WPQgRBPI0g19aynN9Hpy+2vyYZtG/Hk6sEc6S8DI0WAOmuhmroFxhB0BfRK8Q9b3bvOtFMQ1POVo3o1/1BPd/4lPIn6CxhXUcnHoUjVfhmo6NEtFMQ6IlIr6j1a4GA1W/YrRFESiiLIggCrqghsKJ4EjQNOcM63XitngQ6ecypEfjqlV0f7FBTfc1I+K0S1EKEm4a0oHb2OegOQUHgKqURiaAgSHPHNEO/wAiCvoieID56q5vXieIszimGk78M215UwmbVg2p/iGkoAUGQ6ci4LTtGbUM0AmuVrFfUemJqrla1gpwagU4oc5szQjQCx6Slo4a0jwBg6EQYMi72mMM0ggiCQPc/1qGizqghgGe+AcNnw+jjrbFH0WYgNGmtpwRBlitxLhJaEJh8AwNGEPRNmq1S2ynTCFymIW8+nPBFKBgBT34R9q1RjVeaDinbuz9B0xDY5qGJp6ttJEEQ1AisyVJrEG4fAdKe4N3XcI4fHOGjDtPQssdg6Y9ijzcrV03asbKno2kEWiBkeeHyP9mZylm5sU1DYYLAeu+gnb4usd4O8QjTCJzaWQdsed4WtMY0ZHBgBEFfRE/gR3fZq/Su4HYWB8MeC5RJ5PRvKXOQJx9OvEHZw+v2KPtyIhoBQIm1Ap+0OPS9wI4CcmsE7hwCsJPA3JFDTidsRB+BwzTkybH7H0fDk6vGEVMjKFB+AD1Z6vGXT1VhqpeusIvQ6feNZRrS5ievK0dBfz8yoExO3UVrH+5ObACb/wGPfgoOb1TPjSAwODCCoC/SUgvl09Tjj7qoFbS3qQknI0ttpQxfBR97FYyYA8d/Dsot007t9tBj4jHjfJh3BZRNVc+dJpIwjcCaLCMKgijF20I0AmdT+QimoUTw5Fj/Gx01FEMjOLBePc+zeiWNOha+tQcmnRF6fLQ6SZCYRgCpMQ8FeyRE0AiO7FTbRiuj2/gIDA6MIOhrSKlMQ5POUCv1PW8ptb5ub/xznWj/QPFoteLs8Nl9dnXp5EwPfHElnP2/tpmmZqvaZieQRwAw9Ry48JeRV6HRfAQN+5WAync0GYpW1985kUY0DSUrCPIsjcBV68hJdoGamN+4F6afD8UOX0ZGhFsmpiBw+Ag8eYQ0sNeaH0BLqgRBFI3gqBUIoAVOUBAYH4HBCIK+h79ZTSoFw2HMAtj2AvzmTPjp3OSEgZ5ktOnG32zbkCNNZnp1rgVBoqYhTSQHZadLI9CTZeMB5Z9wFrXL1IIggkagV+SpEAR60o6ZR1CozGTeAjjvJ/Gv6cmNXXROv0dGBuQU2eGiadEI8h2CwDEmXQrE6ZfQ5xgGPUYQ9DW0ozi/HMadrG7g6s1qYtLqfSJojUA7c9ubYyeK5ZeDyISaJE1Dmkghi1E1gn2hZiFwaAQRfARBQeCMGorgI0h0nPHyCHR00Lk/goJh8a+ZlR27DLUze7l4DNRbAr2l1haAqRAE7S3q80T6LsIEgTENGWzS2o/A0AX0jZpfBscsVTf1uJPgwTNs23oiNFvXiaQRRCIjEwpHQO029TxR05AmKxsQcaKGtI/gAAyf4Trf1T3MeY3sQuULCMkj0K0qu+IjsPIIMr2hUUeaOZdByRiYuiSxa8aMGmoJFTbFYxyT8hEonaQcuK3dTCoLBCJoBI68jaDwsd7HhI8aHKRVIxBCLBFCbBFCbBdCLI/w+lghxCtCiHeFEOuFEOemczz9Am3SyWlbgDUAACAASURBVC+DvKFw8o2qKxiolXQsOjvghf+G+n3hGoG/xUpuirHSLxxpayTJmoaEsFfbwfFYq/YchyDQZRWcOQRgR/s0HYZHPw0HP1TPO9qsrFxXd69Ov9JgIpm5YuHJU45mX0P05LPcEiWEo1UxDbtmjKihdleF0xKnRlCjch+g+xpBh1VZNkQQWJN800H7u2ipVYKhrUE9N6YhA2nUCIQQmcB9wMeAKmC1EOJpKeVGx2G3oVpY3i+EmIHqZjY+XWPqF+iJOK/M3ufJVeaKxjihpIc3wFu/sCa7DqvFouUE9jfFryFUNBK0rEnWNAThE2KwxIRDEPgalJnKmUMAtkbw7+8qU9ikxTBilrJzZ2XbSV6azvbk/QPO92mp7dpnjHZN2Rl5TP6WcNOQr0Elq7XUKtNTdnF4mYn3HlFO/mOvTGwMzigot0bgbB7UesQqkWHlE6TCNPTuwyooYeJp3b+WoVdIp0awANgupdwppfQDjwEXuI6RgFU/mGIgCdvHAKXFoRE4KaoINw35m+GlO+zVnX59x8vqOnml9sq+vSV+n4FCh90+0YQyJ26NIMxH0Bo5dBRsH0G1Vb7BZ32mjjZlenE3fu9sT94/APYk2XIkfjmKRIlm1goE1ErdqYWVjFHbuj1KC8grs2oYuTSC1b+FVQ8kPoZgn+l8OyrMLQiGTlLCR5uFsnJSoxH85y5Y/WD3r2PoNdIpCCoAZ5hLlbXPye3AlUKIKpQ28OU0jqd/0FwTWqlSUzgyXBBs/Dus/AnssFpPatPR/nWqYF1eWWgNfH9LfI1Ak6xpCOxkLY02R3hy1aTd0WqP0S0ItNO0cJTSZHSFzw5LI3CbhgLtdpvKZMcI6v8cq3dBMkRrV1lvTcA5Rfa+YstUd/ADteLPK1UmQLcgaKuz/TyJ4EyQy8yy+i5Y+3QNqZFzlQDUgqBoVGrCR/1NxsTUz+ntqKFlwO+llKOBc4E/CiHCxiSEuF4IsUYIsaa6urrHB9mjNNeEmoU0RaPCBcHWF9RWh5Xq12VAlafIL7Unu6CzOMYErzWCzOyumV08ua6EMutxVo5apba3Qn2V2lc8OvTc4gplNvn4PSp7V7eK7GhT50fyEXRLI6iN7S9J6ppRGti/9UvlzJ5xob1PawT731XbvFKrvLXLNNRap7Q6XRLivUfhueXRS0sHkwV1jwRHIbyje1QJkeIKlyCoUGN2N6fp7Eiunaa/yRbchn5JOgXBPmCM4/lobAu05nPA4wBSyreAHCBsFpRSPiClrJRSVpaXl7tfHli01ISbhUAJgubDdoXOzna7jLSzb3DhSKtbl7Q0Akc2ayI+AuiaWQjsZC2NHmtWtq0t1O1VTt5Cl0aQOwS+9iEcs8QuAw1qle3JCW/83tnRRR+BQxCkTCPQfYsdkUPNNbDuIZjzqdCEtPxyJdj2v2c9L7X7HGikVBpBR5v9mT/4C7xzP7z588hjcFdT9eTZgqnuI1WML3eo2qezi7Wfxilg2+rhB+NVQcJE6PAroWzCUPs16RQEq4EpQogJQggvcDnwtOuYj4AzAYQQ01GCoO8s+au3RC6NnE6aq6MLArCbvn/0tmVHF3YUSsM+FSU04VT1PL/MXvW2xwkfBXti6IpZCMJbNna0KfNNRqaddFW/V32WSGGbGq0RSBlHI+ii1gLKuZsyH4Fl1nJ+9nd+rca+8KbQY4VQ2tAhKyoqr1RN0E5B0N5ih8fqKLKmw2r779sjFyN0lw9xagR1H6nfhc7HOLJLbfVvyvl/bTyonMnaVxMPLQDSqREc3Q2PXWGyoNNI2gSBlLIDuBF4AdiEig7aIIS4QwhxvnXYN4DrhBDvA48CV0uZjE6aRtrq4f6F8MHjPfu+zbWRTUN6Ba3NP1ufV6aRCYtCNYKiUXYtnLwyFZaZ4VGfp9MXxzTUTUEQKXxU2/61RlBfpUxAsfAWKCHX2Q7IyIIg0J58DoEeR/B9UmUa0hqBbqvZphy9086zazg5KR5jHxs0DdXZJhpd/hrsvJKmQzDzYlXs7k+XwL++G+pD0JpYsFmOJQgCnep/XjJW+SLATkzUIbxOLU6bjRINZ9UmvHRqBDtfhc3/hCPdbNRkiEpafQRSymellFOllJOklN+z9n1HSvm09XijlHKhlHKulHKelDJBfbQHaDmiJpvmHlRQdJ2hWBqBFgTbXoRxC1WOQd3e0Pj8yWcq84vOIfDmQVO1/Tga2QVqNd5l05DLWdzhs/MD9Aq1bm+4fyBsHIVqhalNG1naNOQqMdEdHwGkL2qoZqsy7cy6JPLxJQ5BqAUB0p6E2xyCoLlaTeYtNVA6GT7zlBIwb/wUflFpawd6Ig7WNbK+i8YD6ndcMs7WCI5aGkHhiNBzwSEIHGOIRbDEeRoFgb4HoyXtGbpNbzuL+y56pROvCXgq8TepVXs8QXBkl5pspi5Rq0t/o7q521vUcUPGw5fegdmXqnO8BXbXs3ir4KJRyWcVa9w1d7RZB9QK1d9kma/iaATZher/r298j0Mj0HX7O9tjm5eikeXUCNIUNaQruJZNiXy8jhzyWDH/eqWuV+HOSbi5Rv3JABQOV8L9kt/ADW+oif0P58PKu2HvauszuUxDWlsMMQ3ttAS+q3UmJK8RaAHQ6U+fGVWbx6IV9jN0G1NiIhpBZ2UPCoJgVnEEh3hOsVrtNeyHzc+ofVPPUWGIAB+9o7ZaYDgnIU9e4hnDS+7quskkUvhopkMjOLBF2ebjmYayrebx7U6NIB+QSkvw5nc/aghSGDVkXVP/ZrQgGDop8vFaEOqJWdc2ClYGdZqGamwhXjDc3j98Jnz+X/CXq+Gl/1H7vI6ezZ485U+qsUqGDBlvBRGgrlc8JjS0WNNV0xCoz581NLHzkqHZ8o9EK+xn6DZGEETD14uCIJKPQAg1yTfuV3kCw2fD0An2pLH3bbV1l24ANTlok1K8SV43mOkK7t69HT7bkerJtYVRXI2gSE0qWiMICgJsh3egIwU+ghRpBEPGAcKedGu3Q9Ho6NfXgjA/iiBwawSRBIE+76qnVJ6Ar1El7umKrvq72L1ShY4OnRgaJppTHN4fASKbp2LhNAn5m2ztJpUETUNGEKQLIwii4ddx7D0oCKJlFWsKR8KB95Vp6HSrdJMuKveRFgSjws/z5tvXTpWDNBKePGXaCnSqCcktCDRxNQKrnITuGaB9BGBNPMOUaahLZTDS4CPILlQT7UGrkU3NNlVMLhphGoHLNKQn4+wilyCIUAlViNBuaRpPnoqy2fkfmLhYHZeZpQRAW318QZCwachxbroih4xpKO0YH0E0esNHECxBHUUQFFVYER8Spn9C7csdokwc1ZtBZISvGkHd8DJgP04X7uiZTl9o1JAmnrNYT/o6YiZEEFgTT1fDR7PSEDUEMGK2lS0sVVZ3NP8AKIEuMsJNQ8HKoHWAUBpfNNNQPDy50FClflMTT7f36/eMKwgS1Aick787u/iV/1NJcN3FaARpxwiCaARNQz3444tlGgI74WvIBLsiqRB2dFDB8MiTo3Pl29XQ0ERwt0js8NmOVP1aXmn8CVg7MfX/w+MwDenvJdDRNR9BRoZDOKVIIwAYOUeZaGp3qP7DpZOjH5vpgbmfhskfU89zitXWaRrKLlImneZqlUOQXRwqTOPhPHbi6fbjiIIgQtSQr0El7cXD3xj5Maiwz41P2c/fug+e/GL8azoJdNoLAiMI0oYxDUUj6CzuwSSWxoPqho9mW9b2/+mfCC2RXDIGqjdFNgtB6OSfTo0gGD1j/c86fHadHf1aPLMQ2OGreiWYlWNP3k6NoCu1hkAJlk5fijWCOWq78Um1LY2hEQBceJ/9WJtsWh0aQW6x0gwPb1IaQSINcpxoQVA2NTSzWZuhcorV/1VkRM4j0I+1HyMaTo3AbRryNajwVV+jEu6b/pFccyVQWpLWZo2zOG0YjSAazlo3PUXjATu2OxLa3DDzotD9WiOIKggcE14qV8Fu3OWPQ0xD1vvGMwuBHd3iFATu1WtX8wicY0nl/0ILgg+1IIjhI4hE7hDbNNRapxy/+WXKNNR4KDmzENjfxcTTQ/c7NQIhwvMzdNVXSMxP4DzXnUugq+LWblcms8ObkvcjOPN4jEaQNowgiEbQR9CTGsGB0AqgbiacBl/9ACrmh+7Xq+xIEUMQqmH0iGnIoRG4ncVaaMVCm4aaIgkCrRF0sR+Bvh6kLmoIVIx//jDVEyLTm9jnDDl/pN1voq1OlabOK1OT35EdXdAIrM828fTQ/XkOjUAf5zYN6bDahARBU7i2ptFCpWa7mtDb6lQAgM4FSQQdOgomoSyNGEEQjd7II2g8GN6wxYnTH+AkUY0gw2Nn+qYDd9P0EEGQhGnI6zYNZYc7iwPdEARBjSDFZrIRs9V26EQ7jDNRSsbayV9t9bZGAJZpKEmNYORcpaWMXxS63y0IvPmhNXza6u0opERCSH2NthbrzCkIBOzntdtCaxclk4Ws/UTQsxF8gwwjCKLR087iQCC+aSga+saNZnbRE146/QMQ3iIxJKHMmnzj5RCAw1lcbV83zDTk71oeAdhCKRnnayKMtMxDsRzF0SgZq7KuO9st01BxaGJhshrBuJPhiytDeyFAqGkIwms4OQVBohpBfpkqaRKSU+DoglazTRVwdJ6TKPo3IDKNRpBGjCBoroXffCzcidXTpqGWWhUJ4y7PnAijjoVLV8C0j0d+XU+i6TQLQbiPwFliQodI6h69sXBHDWVlqz/nZNPZxaghsIVSqgWj1gi6KghkQAkDp2lI05UFQiRy3RqBq+R3R5uVIEfiPgJvgVU63ClQHL6G2u2hGkEyfoLmahUUkF9mfARpxAiCwxugapUKdXPi72FncaOV+duVG14IVeBMm2HceHtKI3CHj/rtMU3+GFz9jCqNEI8w01Cu5dh0mDE6/V2rNQThIa2pouI4FYWjBUIy6MTAmm3qN5dTEhqxk6xGEI1xC1WPhJHz1HNvnj2Ba5u+HksiuQS+JiW4vQWuCCLrWkUVKqT2sNM05AozjUXTYSUQ3XWsDCnFCAL9Y3eXuPU5wkd7ojK2bhYSzc7fHXpMEOiEMqdGYAmCzCwYf0pi18nyqsm606e0AD3he/LsbOOulqHW4xQZ0QVnVxkyHm5co8pFJ4v28xx4X21zS1ymoSR9BNHIL4WLH7BNRt58W+vVq/i8UhW5lZBG0GjVOCoIneD1tSrmq++sapWtDSalEdTYzXyMRpA2EhIEQohJQohs6/HpQoibhBAl6R1aD6F/7LVRTEMyYNXFTzMN3dAI4pEuU0i099F18GWnHVGSLM6Wi8F9VtmEQKf6XrpsGspVfhNnLkaqKJ2kktaSpXi0Ek66TEVOSWgj+lQJAjfO8FGdQ5BTpARRIoLAZ3W9y3ZpBPpaFcepbacfKirV42R9BPllliAwPoJ0kegv9q9ApxBiMvAAqgXlI2kbVU/SFkUj8DfZCUs94SdoPAiI9NzwelJNtyBwJpQFC8Z1cbLWfgLnql2vXrVg7qppqHh0Yk7rniTTo8woByxBkGuts/LLQstRpBpvvj0x63shp1gJokSihvxNSgi4nc7aNKQFAcBoSxAkpREcVmaxrBwTNZRGEhUEAavj2EXAz6WUtwAx4hz7EXrVc2SXo9Z9h1JDtWreEypp4371fl0NiYyFt4c0gqAgaA1tXN8VdHax83yPNdl0WnXvu6oRnLYcrn2ha+emk5KxdtOYHIcgyC9PPhw1UTx5ETSC4vA+ypHQ/Yq9heovUqmKsqn2QiSoESThIwiahrKNRpBGEhUE7UKIZcBngX9a++LOWEKIJUKILUKI7UKIsOpTQoh7hBDvWX9bhRAJVrpKIdpH0OlTRbrA/qFqQdBTGkE6zELQcz6CjAyrRWJL9yfrbFdpCrAdm7qfb1d9BFne8LDKvoAzR0QLgpKxqrZUuvAWqO+qsz26INj4tO3DcqIn/uwCu4eERmsEOcXKXOYtsNt2+hIUBP5m9VvK185iSyOQUlXb7SNdbQcCiQqCa4CTgO9JKXcJISYAf4x1ghAiE7gPWArMAJYJIWY4j5FSfs1qUTkP+Dnwt2Q/QLdxrnpqLfOQ/qHqSI2eiFZoOJAeRzE48gjSHD4KdnRH0DTURR9B0DTk1AjyXEImDdpTb+IUBNo0dN49cNkf0veezoztEEFQohZJ9VXw+FWwZkX4uVoQePPDS1W0NVgJjDkw5Rw4Zqk6TmQkbhoKVuN1aQRVq2HFObD3nfBzDm9OrFhePPa8Bbtf7/51+gkJCQKrt/BNUspHhRBDgEIp5Q/inLYA2C6l3Cml9AOPARfEOH4ZqoF9z9JWZ2e7aj+B/qHma0GQJtvk7jfgle+rx11NJksEZ9eqdKMb2DubynSFoLM4J3Sfv9nhIxhogmCc/VjH+eeXpu93AbbZ0N+sVvEiU32HWiPY9Zp6vX5f+Ln6PtGd0fyu8NGcIuWQP+O/VXvNYG2jBAWBLjGSP0xpmtrcqAWELsmhqfsI7j8JNv09sevH4uU74aU7un+dfkKiUUP/EUIUCSGGAuuAB4UQd8c5rQLY63heZe2LdP1xwATg5SivXy+EWCOEWFNdneJm8q1HoXya+vHryCH9Qy1Is2nog8fh1buUg7ClJnZ5ie7gyYEzv2v3ME4nnhxr1W4Jgi6bhiJoBF63RpDGchm9gdYIvAU9J+ScpTt0wxohlCAItMOW59TrOs/FidYAsgvVX0ebvRpva7DNe+73S1ojKLM0grbQ99VF+jQHP1DRZHV76TZtdelrtNMHSdQ0VCylbAAuBh6SUp4AnJXCcVwOPCGl7Iz0opTyASllpZSysrw8Qj/f7tBap370Qyc6NALLvqk1gnQ5i3Ws9euWTE2XIABY9HUYNj1919doW253NYJopiF/i8NHMMCqqGtBoLWBnkBri+0OQQB2Jvi2f6ltQyRBYJlQdR6Bc5/WCNxkFybuLK63fHaFI0LzCLTp1u3MPrxRbXU3vu7ga7BzVpxUb7H/JwOIRAVBlhBiJHAZtrM4HvtQYaaa0da+SFxOb5iFIFQQ1LpMQ0EfQZo0Ai1wNljNO9IpCHoKbcdPWfioUyPIVzdnRze1jb5KUYUyzeT0YIqO20egBYEeQ0erighqOBB+rs/hLHZXh42mEbjzDWKxb61ajBWOVJqm/t71e4QJAit7ubk2sevHoq0htBif5o2fwt+/1P3r9zESFQR3AC8AO6SUq4UQE4Ftcc5ZDUwRQkwQQnhRk/3T7oOEENOAIcBbiQ87RQQ6VTep3BIV2XB0t1JttWlIV39Ml7PY12glXFnRD7FKUPcXPJYtN2ga6q6z2HG+9nFoATrQfASZWaqJTG4vCIK2hsgaAcCMC9R94p7Anc5iHe6rj/E1RNZskvER7Fujcg+EsDUCKWMIgk1q29JNQSClujcjLQDb6kPrKA0QEnUW/0VKOUdKeYP1fKeU8pI453QAN6IEyCbgcSnlBiHEHUKI8x2HXg48JmUvxILpKIncITB0krKJ1u+N4CxOk0bQ1gCTFtvFxQaCRqDDR7sbNRQxs1hPWtb3NtAEAcC8K9XE21OUTlHCeud/LEFgreK1ICgcCRNOVY/dzlk9Ies8AnAkp0URBNmF0TWCQMDRM/moKlanE9L076jDZ7+H00fQ2a7KXUP3TUPtLSor3t8cHqLqb1JaUk9UG+hBEjKyCiFGo8I7F1q7VgJfkVJWxTpPSvks8Kxr33dcz29PdLApR68ockrsiou1O2wbZLoTynwNKmP02Cvh3T/alSH7M2E+ghRqBFoQ6NyPruYR9GVO/1bPvl9OEUw9Bzb8DRAOjcDSSiacaoc1N+y3u+SBfZ+EmIYcGkE0Z3E0H8G7D8ELt8FX3rNrLuls5CxHHSv9Hq0OQXBkp132vLsaQXDFL9W971yMBDWeRru3wwAgUdPQ71BmnVHW3z+sff0bnUKfO0RlQALUbFE/1Mxse3WUTo0guwjO+H/wpVVdq1HT19Dho8HInu4KAsdNqE1D+nsbaD6C3mL2J1WETvNh2zdQMBzGngRzl9mCIEwjaFI+jaycUNOQbkoT0Vkcw0dwaIO699Y/rvwDCFViHUI1An2+0zSkzUKjj+++j8DZrtPtJ/A1hh8zAEh05imXUv5OStlh/f0eSHH4Ti+gf0i5JXYq/+GNVmndAkfJhDRoBIFO9aPPKVK2Ye2P6O8ENQJdYiKNGsFANA31BlPOtlfvWiPI9MC1zyvTpTZZNlixHlJadnTrPtH5AaCEg25KEzV8NIpGoHMV3v0TVK1RizM9Hn0vdrRFDh89vAkQMPZE9f7dKUfhHJ87csjfFH7MACBRQVArhLhSCJFp/V0JpMA138u0OjQCUOGVhzepL9tr/cB1FEyqCarVfbDUQXfw5KobddM/rQiYLn4+LQg8kTSCAewj6A08OTDdcttFdPDmqf0NB5QAuG8BvPoDuykN2N+Xr9E2rUTTCALtkSfq+r3qN3N4A+x8xTYL6TGCWpT5HRqBtuFXb4KhE+wufd0xD+nfF0Towzy4BcG1qNDRg8AB4FLg6jSNqedw+ggAhs1QIWjO0Ld01UH3xbhZ+jOeXBUxtO0FWPqDrsfE6wkmkkagb9SB6CPoLXSyYTQ/VVGFMg3V7oCarbDqAWWjd1e21RnKEEUj0AIjgnmoYR/MOF+ZEzv9oZVLQzQC61zZab/X4U1QPt0OvGjuhsM4mmlISkeexCAUBFLKPVLK86WU5VLKYVLKC4GYUUP9gqCPQAuC6UoVPLzBtnlqm3fK3zvGzdKf0SvD05bDguu6fh1tqhs6yd4XFATGR5ByJp4On/oTTDsv8uuFI9VE/ZEV5d1SCzteDr1PRIaapONpBBDuMG5vVdccPhOmWy1XQwSBM2rIsUpvPar21e5Q9682sXZHI4hmGmpvVZnL7mMGAN1Jzfw6cG+qBtIrtNapH7D+kQ2zauLVfQRlVqVEXTIh1QxUjWDup1WG7PTz4x8bC08u3LLdtc8yDQV9BAMss7g3EQKmfyL660UjlTP3o7eVKTUrV5Wd0BqB9hP4mhwaQZQ8AgjXCHTmctFomPYJtbJ3tvwMiRpqVtF2LbXKT+C3wj3Lp9l9G7plGoqiEbhrKQ0guhOmkob2Tj2MzirWlE+zHztt1OlwFrfFuFn6M/mlKg4+Hd2/vCZqqNcoqoCmQ7B7pYommrdM7df3CdiF52JqBK58A40uJ1FcAcOmwbk/DO3BEDQNWVFDulBk61G7h0PpRNs0pAVBy5Hky1U7J3mnRhBSZntgaQTdEQT9vxh469HQdP6cIvsHFmyMkms0gr6Cx/gIeo3CkYCEuj0qMmfeFWq/s8eFzhr2Wd9PxBITUXwEWhAURaxLaWvt7VYeQYlDEByxBMGQCZaZVygfgb8Z7p2jHNvJ4Jzko2oEg0gQCCEahRANEf4aUfkE/Zs2l0YAdmE2r0MjSIezuC3GzWKITJZXTf4mfLTncfbKGHuyKsmy+L9h9mX2/pKxsG9daO9jN+7idBodmhpNEOjosbZ6ZQYqtgr0aY0g22qmk5GpEr1aaq0IwEZ48+fJ5Ra0NYS2XdX4BqkgkFIWSimLIvwVSin7v4G29Wh4XRctCEKcxUYj6DN48+zetUYQ9BxaEGTlwMi56vFp34QpjiLEcy9XGsOW5+ymNG7cNYk09VUqOMATpVqt1gh0+YhgmOgRpREMHW+bI/NK1XEHP1DP/U3wRhLuTF+93QPC6ZgerBrBgKe1LlwQlGtBoDWCnPT5CKLdLIboeBymCOMj6DkKLUFQURm9ouz0T6iVedVquymNG2fi2eHN8P5j6nnDvujaANj3iV7Z55Yobbr1iCoW6WznmVemjju0QWn2sy+DVQ9C46HEPquv0aozJlwagTX5Z2SF5hoMAAa5IDgaXvI3aBpyhY9KCU9/2e7Y1F2cHZwMieN1dFkbaP0I+jJ5Q5UwmHp29GM8uXY+QjSTp9NH8NqP4Mkvqn7I9VX2Kj8SWhBojcCbr0xBzTUqym+oUxBYpqFDG2D4DDh9uTLvvvuQfczjn4W1UVqAtln3prcg1EegBUHhSKMRDBg6fMrE4PYRjJgDZ/0PTLNimbNy1HGtR2HdQ7D5mdS8f7R67YbYaOdkhscI0Z5ECLjpXTjpy7GPO/ZKtY1m8sz0qIQxX4MKRUXCpn+o8hIJCQJLI/AWqHv30IcqU3nIePvY/DJVO+nQBhg+S/kzCkfaHQg722HT0yp7ORK+BiWwvHmhUUPaNGQEQf8mEHAEOrW6ksk0GRlwylftNpW6do4OUWtKUL2MR7QOTobYaNOQ8Q/0PJ6c+IURRx2rFlOFMWJJsgugejM0WJFC7z2snLqxTEOZWUoD1BnD3gK18q/eop6HmIYsH4GvXiWogXJk11stLBv2q8Swpihtb32NapHmyQv1EWi/RuEIIwj6Ky9vPsTCH7xMTZNV4yRYcG5I9JPAEgQtdohatB9PshiNoGto05ARBH0TIeCqJ+HCX0Y/xltgm1innAP731WPi2MIAlBaQVAjsExDOop9qMtHoBk+S21LxigTEtjb5sOR3ydoGsoPDx/15KnFoxEE/ZOxQ/M5UN/Gn1dbqwJ3naFo6LA1vfKIpRF0+FRV0UTwNfZsb9qBgs4uNjkEfZf8sti1+nWj++wiZb/XFMUwDYGKHNKCILvArouU4QnVJnR2Mdg+v+IxyiEd6LQFQaR7ubNdmYKziy3/oCuhzFugxm0EQeIIIZYIIbYIIbYLIZZHOeYyIcRGIcQGIcQj6RrL5GEFnDyplEfe+YjOgFSNLCDUthgJPfHoxthNUVYRne3w4Bnwj68kNqBojTsMsdFOfKMR9F/0dzjmBGVKKrFyAuJqBI7kTm0aAtVUypmFnG8JgpJxtvm1ZAwEOlThPG0iaqsPr4IarAps+QjcGkF2ofprb0580dcPSJsgEEJkAvcBS4EZwDIhxAzXMVOAbwMLpZQzga+mazwAXNjRxwAAIABJREFUV504jn11rbyy+bCyUWZ61Y8lFtpJVW01xvbVRy5Ct+4PynG1+/XEBtNmfARdwpiG+j86l2DcScqUNPuTalFUMCL2eSGVaAtss657Mac1AmetIi1s6vbaGgEop7ITZzKcJz88oSy7ILTk9gAhnRrBAmC71d/YDzwGuJuxXgfcJ6U8CiCljLLcTg1nzRjO8KJs/vj2HlVKt3RK/MJlWiM4slPVSodwraCtAV75vqq+eHRX/ObWgYDRCLqKMQ31f/REOvZktT1tOfzXW/HvRb0oE5lKKGjTkNNRDLaPQDuKwc5ErncJArd5yFlC25sXnlDmLbTvWyMIEqIC2Ot4XmXtczIVmCqEeEMI8bYQYkkax4MnM4NPLxjHq1uraT+4CcqnJnCS9eOTARg5Rz3WgqB2B2x4Cp75hopSOM2yfh36MPY1/U2ANBpBV9DhoyaZrP+SXaRCSINtKL2xQ0c1+l7UTaO0RjDUJQiKR6vyFzqUVe8Dlflc9xEMnaieu4M/nKYhd1UBX6PRCNJEFjAFOB1YBjwohAjz3gohrhdCrBFCrKmu7l7UzqWVo8nGT1bDR6HVRqPhcSQwjTlBbfUq4vfnwV8+Cx88DpXXwvzPqP06tT0awVVHYezjDOHo78OUoO6/nPhfcOmK6OUkoqE1Am1a0pO7+z4WQpW/0OYgUKv7vDKVhdywT2VIQ7hG4Kyc6o4aCjqLtSAYOKWo0ykI9gFjHM9HW/ucVAFPSynbpZS7gK0owRCClPIBKWWllLKyvLx7rZIrSnJZOrIRgbQb1sfCWQJizAK1bTqkapw0HoBTvg7f2ALn3a3ii/PL4cD62NccqE1pegKjEfR/hk2zm88kg/YR6N/A8Bnwhddg0hmJnV8yBvauVk5j3QbTHULqbCGro4Z0GWu/9hEY01AyrAamCCEmCCG8wOXA065jnkJpAwghylCmop1pHBMAHx+pvsCD2ePjH+zUCEYfDwhlGqrZpvaNPVEJACHU34jZcPD92Nc0Bee6jjOz2DC40M1pdNQRqAJ4iWaYl4yFGisMvHSyChENMw25fAQyYEcW+ZriawRHdsKrP1R+wH5E2gSBlLIDuBF4AdgEPC6l3CCEuEMIodtXvQDUCiE2Aq8At0gpu9FaKDGOzz9MpxT8c19u/IN1HkFWjopzzitVGkGtJQhKJ4ceP2KOKqbV4Y9+zYHalKYn8JiooUGLWyNIlmKHgaJknKoeEGYackUNgfITdHZY+QWFsX0E7z4Mr3zPDjeXUvkS+zhp9RFIKZ+VUk6VUk6SUn7P2vcdKeXT1mMppfy6lHKGlHK2lPKxdI5HU9y0kwOZo/jnhiPxD9Z2zJJxKr2+YLitEUQKPx0xW9U+0eGmkTAaQdcx4aODl6CPoIu+NafPoHi0upfd4aO+RuXIzsq2BY6/ya4z5I3jLNYax5431Hb9n+Hnx0H11q6NuYfobWdx71C9Bf+Qyby3t46qo3F6DegVqI5VLhimVhE121TkgdtpqWu1x3IYm6Y0XcdjfASDlmDUUDc1goLh6lr55eGh4LrgHNiLDn+LLQiyCxx9lyMJAstSsHul2m76ByBh53+6NuYeYvAJgs52OLKDsglzyMwQrHh9d+zj9SpEh6hpjaB2W7hZCJRw8OTDB3+BlT+B9Y+Hm4mMRtB1gj4CEzU06MjqpiDQGoHeFgyLnBOk78ugaajZLjjnLVCWAW+hEgSrfwO/PEn5BDo7bDPQnjdV4ukOq8KpFgzNtfDPr8fPNephBt/dVLsDAh0UjZnFRcdW8PA7e/ji6RMZVhgllC27EEYvgImL1fOCcmg6qGx/084LPz4jU0UX7XzFLnP7r++oOu3DZirTUWudSopxOqINiWGihgYvQR9BQezjoqH7HAc1g2FWpYA2W9vQlUchVCPQkUNaW8gpUgu6tX9Q/oCarereD7TDuFNgz+uw+rdKiBRVKFNRIABrV8Ca38K4k+3eDX2AwSMIpFS9BJ77lsoArjiOGytG8eS7+3jg1Z3c9vEZkc/LyITP/8t+XjAcOq0VfrTw02WPqnK5eaVqZfDWL+DtX6kfiSZ3iKmn3xWMs3jwEilqKBlyimHYDDsMPH+Y2jYftrWEtnpHd0KHszjQoR7r17IL4dBGOGiFiletsjOdK69RgmDlj9WYT/kaPHszVG+C9/9sHb86uiDYtxaGz47eCS4NDB5B8O6f4Okb1ar80t9C2RTGAxfMG8Wf3tnDVSeNY1xpAipnwXD7cWlYyoPCk2uvPqacpf4621Vo2f53lXBwOq4MiWOcxYMXrRFkd1EQgCploSmwBEFTtbofpVRBHjOsSjhBjaAZMq3FnxZC2YVqMgdlstq7ys5WnnK26sfQuB+mLoUpH1P73/y5MilnZKnjI3FklypeefJNcPb/dv1zJsng8RHMvAjO/TF84VUV+29x0xlT8GRkcN7PXucva/YipYxxEewfD0BZBB9BNDI9UH6MavB9/s/g1JuT/AAGwF6lmTyCwYcO5e6qj8BNgUMjALVQa6uDiuOs97MEQXuLI9HMIQhAZTVPOFUJhZqtSgDkFMH4her1qeeoyMLiMfD+oyoiaf5nlCYRqXil9iWselC18ASVvJrmvITBIwiyC2DBdWEryfFl+Tz7lUXMGFXELU+s59evxcln0xpBXln8pjaG1JOZpW4m4yMYfHTXR+BGm4Z0LoFukFMx33ofHT7a4nAWO0xDoPyEoxcoTaJqNZRZVoKpS5RZaOoSZQIef4raf8xSmHyWMjUdiJB4uvsN5aMItMNrP4b1f4GfHAMv3paazxyFwSMIYjBmaB6PXnci580eyQ+f38wb22uiH6wFQSLlKQzpYc4nYcKi3h6FoafJchSdSwX5VrkanV28b52avMutZjZBjaBZtdKEcI1g2nkw5nj1uHa70voBZl0CN2+FopHq+Xjr9zr3cqtCAbZpycmeN2DSYlUwb80K+Nvn1Zje+ZXySaQJIwgsMjMEP7x0DpPKC/jyo++yvqou8oG5Q9RqNBmzkCG1XHAfTP9Eb4/C0NN0N3zUjSdHOZCDGsE6VWFY5wZ5cgFhawQi0x7DyHnKhDTyWLUV1lSqF4hChIaHz7kMLn9EaQgFw5S5SPsJtDn66B5VJnvcKXDqN5XQmX0ZfOkdda3nvmkfm2KMIHCQn53Fr65S9sHzf/EG1z20hgP1LjueEHDxg7AwrT10DAaDG23TLxyZumuWT1Nh3h1+2P8ejJpvvyaEXYpaF5zTkX4LroPrXlY5BdmFKhoJolsKMj1Ke9Dnj1mgNILVv4UfjFOJZ7qp1fiFqlvbzdvgkgeVVnHGbcp/sOHJ1H12B0YQuJhUXsB/bjmdr501lTe21/DZFatoaGsPPWjmhVA6qXcGaDAMVsaeBDeuTayPSKIsuF6ZdN78qaolVDE/9HVvnhICvibbPxAJbe7RpqF4jD5eVS9+5utKCD19E2x8SlkctGnK2ZHtuGtUGfzWBMridIHBEz6aBEU5Hr5y1hQqxw/hsytW8V9/WsdJk0p5efNhFk4u46YzJpOVmbwMbfV34uvopCTPODoNhqQRIvUm2RkXwr9vVxVDIVQjAKURtB5V5atjCaAF10PRqNDw8lhMOlMVnTzxBrWw/PVpsO1FmPZxpWW4yciEa56P/FoKMIIgBgsnl/F/F8/mm0+s5/XtNUweVsDPXtrGm9truO7UiYwoymFEcQ6l+V5e3VrN79/czaGGNobkeTlu3BA+v2giQ/PVpL9q1xG+9uf3aPZ38MdrT2D26GL21bWyv66V48erRJTNBxtYvfsoV54wFmGSzQyG9JOZpRrlvPBtNTHrXACNNx+2PKeSSC+8L/p1hs9Qf4lSNhmW77FNRWd+B178bxi3MPo5aRICYARBXC6rHMOYIXlUlOQytjSPv7+3j/9+8kO+8Me1YceOKs5hVkUxtc1+7n91B394czcnTizF1xHgzR01jBmaR0F2Fp9+8G0uPLaCP6/Zi78jwLIFYzl+/BBuffID2toDNLV1cMPpxvRkMPQI86+C/9wFFceGT7befCUEKirtMjOpwrnYO/EGFcU07dzUvkeiQ4mbQNXHqKyslGvWrOnVMTS0tbO7pplDDT4ONrRxuKGNKcMLWTprBB7LZLTtUCM/f3k7Ww81ku3JZO7oYr65ZBr1re1c8eDb7K5t4ZL5oxma7+HBlbsAqBw3hNICL//aeIg/XLuARVNCu7E1+zrYVdPMrArVxyAQkLy2rZpZFcWUFWRjMBi6yN7VKoLIbf75w/mw61X49F9g6tm9M7YUIYRYK6WsjPiaEQQ9T31LOzXNPiaVq5jkN7fX8O7eOq5bNJGOQICL7nuTqqMtXHBsBadMLmNXTTNr9xzl9e01+DsC3POpuVx07Gh+s3Indz6ziQwBJ00qZcqwQkaV5HDx/NFGMBgMqeDZb8KhDXD1P/t9bTAjCPoZVUdb+NELW3hxwyFa2zsBGF+axxnThrPuo6Psqmnmt5+t5MrfvkPluKHMHVPMvzceZn9dK42+DsoKvPzok3NZfMywOO9kMBjiEgik1T7fU/SaIBBCLAF+CmQCv5FS3uV6/WrgR9hN7X8hpfxNrGsOBkGgafZ1sPVQIxPLCyjOVaUxdlY3sfSnK+kMSHI8mbz4tVMZVWK33Nx8sIGvPvYemw82snTWCG46cwrTR5q+BwbDYKdXBIEQIhPYCnwMqEI1s18mpdzoOOZqoFJKeWOi1x1MgiAa2iR054WzuPLEcWGvt7V38sv/7OB3r++i0dfBqOIcJpTnc8G8Ci6ZP5rMjP6t4hoMhuTpLUFwEnC7lPIc6/m3AaSU33ccczVGECSNlJId1c1MKs+PGWZa39LOn9d8xKYDjXy4r55th5uYPrKIaxaO5/RjyqM34zEYDAOOWIIgneGjFcBex/Mq4IQIx10ihDgVpT18TUq5132AEOJ64HqAsWNNHX8hBJOHxS+8VZzn4fpTVRiqlJJ/rD/Aj1/YwjefUM00RhTlMLIkh7mjSzhn5ggKc7KCpqh5Y0rS+hkMBkPfIZ0awaXAEinl563nVwEnOFf/QohSoElK6RNCfAH4lJTyjFjXNRpB95BSsvFAA69urWZndTP7jray7qOj+DpC651/8rjRfPvc6cGEOIPB0L/pLY1gHzDG8Xw0tlMYACllrePpb4AfpnE8BpQ2MXNUMTNHFQf3Nfs6WLmths6AZPKwAp56bx8PvraTt3bW8uh1JzJmqOmtbDAMZNKpEWShzD1nogTAauDTUsoNjmNGSikPWI8vAr4lpTwx0vU0RiPoGd7fW8dnVqwi35vJd8+fyaGGNsoKslk6a4Qpf2Ew9EN6RSOQUnYIIW4EXkCFj66QUm4QQtwBrJFSPg3cJIQ4H+gAjgBXp2s8huSYO6aER647gSt/805IOY0FE4byuVMmUN/azrDCbE43uQoGQ7/HJJQZYnK4oY3t1U1MLCvgP1sO8/3nNlPfapfl/sKpE/nWkmlkmJBUg6FP01s+AsMAYFhRDsOKVJjp5QvGsmTWCHZUN1FekMODK3fy69d2svFAA5+sHMOiyWUMMc5lg6HfYQSBISlK8rwcN06Vzb7jgplMLM/nZy9tY+U21ed5Ylk+MyuKGTs0l9kVJZwzc7jxKRgMfRxjGjJ0m86A5P2qOt7aUcv7e+vYdLCB/XVtdAYkP718HhfMq2DvkRb+9M4ePrdwQlDDMBgMPYcxDRnSSmaGYP7YIcwfOyS4r70zwKd+/Rb/76kPmVRewJceWcee2hb+uraKez41j+PHDyU7K8NoCwZDH8BoBIa0saummaU/fY32Tok3M4M7L5zFL/+znR3VzQB4MzNYNKWM8+aMZNGUcsoLTelsgyFdGI3A0CtMKMvn/318Bt97ZhO/vGI+px8zjCWzRvDUe/uob23ncIOPFzcc5KXNhwGYMqyA28+fycLJZb08coNhcGE0AkPaae8MBDu3uQkEJOv31fP2zloeX7OXqiOt3POpeZw3Z2QPj9JgGNiYxjSGfkF9Szuf+8Nq1n50lDOnDWfprBFMG1nIiKIchuZ7EULQ1t7JX9ZWceKEoUwZXtjbQzYY+g3GNGToFxTnefjj507gnn9v5R/v7+ffmw4FXztmeCHnzBzO39/fz57aFirHDeGJG07uxdEaDAMHoxEY+iSBgKqSuvdIC3uPtvD8hwdZ91EdE8vyqRw/hMfXVPHkf53MsY5IJYPBEB2jERj6HRkZglkVxcyqUFVSrz91EjVNPopzPfg6Ajz34UF+s3IXP7y0kFuf/IBMIbj2lAnB4w0GQ+IYQWDoN5QVqPBST2YGnz5hLA++tpOdNc1sPdRITlYGf3t3H5ceN5ofXjLH1D4yGJIgciiHwdDHufrk8WQIwa6aJh646jjeuvVMrj91Ik+sreKu5zf39vAMhn6F0QgM/ZKRxbk8+NlKhhVmB5vsfHvpNFr9nTzw2k7e31vHkWY/zb4OsjIzOHlSKXdeOIusKGGsBsNgxggCQ79lsasXghCC28+fiUSydk8dE8ryKczxUN/azmOr9+LJzOCOC2aashYGgwsjCAwDiswMwZ0Xzg7b/3/PbuKB13ZS3eij2d9BjieTLy2ezLwxJb0wSoOhb5FWPVkIsUQIsUUIsV0IsTzGcZcIIaQQImJok8HQXZYvmcZllaN5Y0cN9a3trN1zlAvve4Mv/HENWw81hhzr6+hkd01zL43UYOh50tmzOBPVs/hjQBWqZ/EyKeVG13GFwDOAF7hRShkzScDkERhSQZOvgxWv7+LB13bS5O/ggrmjuGbhBLxZGXz1sffYeriRP33uBBZOLqOhrZ1XNh/mnJkjyPFk9vbQDYYu0SslJoQQJwG3SynPsZ5/G0BK+X3XcfcC/wJuAW42gsDQkxxt9nP/qzt4+O09NPs7EQJK87PJ82bi7wjwly+exI2Pvsv7e1Uy212XzGHBhKG9PWyDIWliCYJ0moYqgL2O51XWPufA5gNjpJTPxLqQEOJ6IcQaIcSa6urq1I/UMGgZku/l1nOn8/atZ/K/F8zk+kUTeeGri/jlFfOpbfZx5t2vsnF/PTefPZX/396dR1dVXwsc/+7MZCAhA0lJAkkQ5CEyI4hKnVBofeJSnorUOlB9tSpWrVXrq6va9r3a12Ur6tNabZ2xylOLPKtFBusAChgDCVOCEMgAGchM5rvfH+cQLpgIapJz8e7PWndxz5Bz9/2Fk33P73fub7d1+rj0j2u4eXEuu6sPeB26Mb3Gs3vpRCQEeBC4/Wj7quoTqjpZVSenpKT0fXAm6MRFhXPlqVnc/Z1/ISk2kjHp8dw5axQCPHrFRG46ewRv/3gGN541nOWb93LOg6u5740C9je1feFxt5TX09Le2T9vwpivqC8TQSmQ6bec4a47KA4YA6wWkV3ANGCpDRibQPGDM3LY+IvzOO+kNABiIsO44/xRrP7JWVwyMYNnPtzFt3+7iufXFuPzKbm7a7h5cS6f7K4BYPnmfcx+6D1ufyXPy7dhzFH15RhBGM5g8Tk4CWAdcIWqFvSw/2psjMAcRwr3NfCLNwr4oKianJQYPnMrr8VGhvGfF5/MPa9tAoWG1g4evWKi1VgwnvJkjEBVO4CbgLeBLcDLqlogIveLyIV99brG9JcRqXE8v2Aqv7n4ZNo6fPzw28N557YZJMVGsHBxLiEiLL35dE5Oj+fnf8unsqHV65CN6ZZNQ21MLyurbeZnr21iwenZnDEihe37Grjg4fdJHRjJHy6bwKRhNnW26X9e3TVkTFAakjCAp685hTNGODc2jEyNY/F1U1GFS/+4hkUrCun0OR/AqhtbqW60KwXjLZtiwph+MGlYIm/ecgb3vp7Pg8u388/tlSRER7By6z58CkPio5g/bRg/OnN411xIW8rrefqDXdQcaGPGyBTOG53K4IFRHr8T801kXUPG9LPXckv4+esFRIWH8G+TMxkUHc57hVW8V1jF1dOz+NdxQ3hoRSH/3F7JgPBQEmMiKK1tJi4yjN9dOo7z3buYjPkyrHi9MQGmrcOHiFNkB0BV+fX/beHJ93cCkBgTwYLTs/ne1GEMHBDG9n2N/HRJHnkldSw8+wRunTkSEUFVyS+t5+X1eyirbeaBuWO7CvgY488SgTHHAVXlubXFNLd18r1pw4iJPLzntqW9k5+/ns8rG0q4feZIrj09mzuW5PHmpr1EhjkJJTMxmhd+MJVUvy6kTp+ypbyekppmzhudatXbgpQlAmO+IXw+5Sev5PFqbilD4qPYW9/CbTNHcuWpWWwtr+fap9cRHRnGjBEpDEmIIq+kjk+Ka2hs7QDghjOHc+esUR6/C+MFK15vzDdESIjwwNyxNLR2sG7Xfp659tDdSVNzknjxumk8vLKQd7dXUN3UxompcVw0YQhTshL5oKiKx1bvYHBcJBUNrbxdsJeZo1O5/owckqw7KajZFYExxyFVpa3TR2RY99NiqyqtHb7Dps1u7/Rx1Z8/5sMd1YjA+MwEPt1TS2RYCGMzEhibHs91M3JIHRhFQ0s7v31rG02tHSTGRDAyLY7JwwaRnRzTdVeTz6dUNbZSWtvMZ5VNbK9oYGx6gn2DOkDZFYEx3zAi0mMSOLj9yNoJ4aEhPDZ/Ei98XMz5J6UxPCWWoooGnl+7m7ySWp5dU8zf8/eyaN547l+2hYLSOtLio6hubKPZnThv/tSh/OqiMexvamPen9ayfV9j1/FDBHwK727P4P45Y6x2w3HErgiMMQDkl9ZxzdPrqGxoJSI0hEfnT2Tm6FR8PmVHZSPPrS3m2TXF3HruSFZvr2BzWT13nH8iWUkxZCVHk5kYzcMrinhkVRHjMxN4bsEpxEWFdx2/oqGFtg4fGYOiD3vdgrI61uyo5trTsm0guw/ZYLEx5pjs2X+AXy7bzPxpw/j2yMOnfPf5lIUv5bJsYzki8Nj8icwa8/luoLfyy7npxVwmDE3gwUvHk7unlqWflrFqWwWRYSE8t2Bq1zQbpbXNzHnkfaoa27ht5kgWnjPiqN1e5quxRGCM6RUt7Z3c/eompuUkctmUoT3ut2xjGQsX5+LOpEFybCSXTErn7fy9VDe28fiVk0iLj+LmF3PZs/8AU7ITWbWtgjtnjWLl1go2ltTywCVjmTP+UC2r1o5OWtp8xEeH9/Cq5otYIjDG9Lv3C6vIL6vj1JwkxqTHExoilNY2c+njayitbQaccYWnrp7CtOwk5j7+IQVl9QyOiyQtPoqNJXVcPDGdptYO8kvrKatzfubeC0ZzzWnZqCrF1QdIi4+y8YhjYInAGBMwKhtaeb+oEp8PclJimDDU6SaqaGjhw6JqZo1JI0SE+94o4MWPdzMsMZox6fHkpMSSX1rHyq0VXHtaNnkltWworiEiLITxGQmckp3I+MwEag60UV7XwoXjhpCVHHPYa/t8ighddz4dtH1fA59VNjJ4YBQ5yTEkREf0W3v0F0sExpjjUnunr2sajoPLt72cxxt5ZXwrPoqrpmdR3djKxzv3k19W3zWrK0BCdDhPfn8yk7MSqWxo5S8f7OTZNcUkxkQwZ/wQLpuSScagaN4rrGTB0+tp6/R1/WxOcgzjhyYwYeggpmUnMiI1rl/fd1+wRGCM+cbo9Ckf7axm4tBBh3UJNbZ2sLmsnqRY59P8dc+sp6SmmfjocCobWhGBWSel0djawQdFVYSFhHDRhCEszSsjKymG/7r4ZGoOtLF1bwO5u2vJ3V1LlTtF+MjUWKYPT2ZQdAQNLe2sL66hor6FlLhIBg+MYnBcJLFRYdQdaCcsVLjujByGJR26Guno9LGzqulzCWVXVRO/XLaZ70/POmxwvqKhhVfWlzB7TBo5KbG90m6WCIwxQaemqY3f/H0rnarkpMR0fXcCnOJBD71TyCsb9pCdHMNf//3Uz03Wp6qU1DSzcmsFyzaWUVBWz4G2TiLDQhiXkUBG4gCqGtuoqG9hX30LTa2dJESHU9/STqdPuXzKUKblJNGpykPvbGdHZRN3nH8iN551AgDldc3MfcwZLxGBW88dybCkaNbvquHl9Xto7fDxrfgoltwwnfSEAV+7PTxLBCIyC3gICAWeVNXfHLH9h8CNQCfQCFyvqpu/6JiWCIwxvaWk5gADB4QzMOrY7kTqcLuPwkJ7rulVUd/Cg8u3s2RDCR1uV9XwlBgyE6NZva2Su2aPIjE6gsff3UFlQytPXT2F59cWszSvDIDwUOHCcenMHpPGrS9/SkpcJI/Mm8iotLiv9T0LTxKBiITiFK+fCZTgFK+f5/+HXkQGqmq9+/xC4EeqOuuLjmuJwBhzPGhp76SoopH9TW1MH56EAjc8v4F3tlQAkDYwikXzJnBKdiKqyobiGmKjwshJjiXCnU123a79XPnUR7S0+xgUHc6PzjyB62bkfKV4vJpi4hSgSFU/c4N4CZgDdCWCg0nAFQMcX/1UxhjTg6jwUMakxx+27pErJrJ6WwVZyTGcmBrXdfeSiDA5K/Fzx5iSlci7d5zFe4VVfPRZNanxfVOhri8TQTqwx2+5BJh65E4iciNwGxABnN3dgUTkeuB6gKFDe/4SizHGBLKo8NBuv439RVIHRjF3UgZzJ2X0UVQBULxeVR9V1eHAncB/9LDPE6o6WVUnp6SkdLeLMcaYr6gvE0EpkOm3nOGu68lLwEV9GI8xxphu9GUiWAeMEJFsEYkALgeW+u8gIiP8Fr8LFPZhPMYYY7rRZ2MEqtohIjcBb+PcPvpnVS0QkfuB9aq6FLhJRM4F2oEa4Kq+iscYY0z3+rQwjaq+Cbx5xLp7/Z7f0pevb4wx5ug8Hyw2xhjjLUsExhgT5CwRGGNMkDvuJp0TkUqg+Cv+eDJQ1Yvh9AWLsXdYjL3DYvz6AiW+Yara7RexjrtE8HWIyPqe5toIFBZj77AYe4fF+PUFenxgXUPGGBP0LBEYY0yQC7ZE8ITXARwDi7F3WIy9w2L8+gI9vuAaIzDGGPN5wXakJpR7AAAGH0lEQVRFYIwx5giWCIwxJsgFTSIQkVkisk1EikTkLq/jARCRTBFZJSKbRaRARG5x1yeKyHIRKXT/HeRxnKEikisiy9zlbBH5yG3Lv7qzy3oZX4KILBGRrSKyRURODcA2vNX9HeeLyGIRifK6HUXkzyJSISL5fuu6bTdxLHJj3SgiEz2M8b/d3/VGEXlNRBL8tt3txrhNRM73Kka/bbeLiIpIsrvsSTseTVAkArd+8qPAbGA0ME9ERnsbFQAdwO2qOhqYBtzoxnUXsEJVRwAr3GUv3QJs8Vt+APi9qp6AM2vsAk+iOuQh4C1VHQWMw4k1YNpQRNKBhcBkVR2DMxvv5Xjfjk8DR9YI76ndZgMj3Mf1wGMexrgcGKOqY3Hqot8N4J47lwMnuT/zP+6570WMiEgmcB6w22+1V+34hYIiEeBXP1lV23CK4MzxOCZUtVxVP3GfN+D8AUvHie0Zd7dn8LBgj4hk4NSKeNJdFpySokvcXbyOLx6YATwFoKptqlpLALWhKwwYICJhQDRQjsftqKr/BPYfsbqndpsDPKuOtUCCiHy5mou9FKOq/kNVO9zFtThFrw7G+JKqtqrqTqAI59zv9xhdvwd+yuG12D1px6MJlkTQXf3kdI9i6ZaIZAETgI+AVFUtdzftBVI9CgvgDzj/mX3uchJQ63ciet2W2UAl8Be3++pJEYkhgNpQVUuB3+F8MiwH6oANBFY7HtRTuwXqOXQt8Hf3ecDEKCJzgFJVzTtiU8DE6C9YEkFAE5FY4H+BH6tqvf82de7v9eQeXxG5AKhQ1Q1evP4xCgMmAo+p6gSgiSO6gbxsQwC3n30OTtIaAsTQTVdCoPG63Y5GRO7B6V59wetY/IlINPAz4N6j7RsogiURfNn6yf1GRMJxksALqvqqu3rfwctF998Kj8I7DbhQRHbhdKedjdMfn+B2cYD3bVkClKjqR+7yEpzEEChtCHAusFNVK1W1HXgVp20DqR0P6qndAuocEpGrgQuA+Xroy1CBEuNwnKSf5547GcAnIpJG4MR4mGBJBEetn+wFt7/9KWCLqj7ot2kph8p2XgX8rb9jA1DVu1U1Q1WzcNpsparOB1YBc72OD0BV9wJ7ROREd9U5wGYCpA1du4FpIhLt/s4Pxhgw7einp3ZbCnzfvetlGlDn14XUr0RkFk535YWqesBv01LgchGJFJFsnAHZj/s7PlXdpKqDVTXLPXdKgInu/9WAacfDqGpQPIDv4NxhsAO4x+t43JhOx7n03gh86j6+g9MPvwIoBN4BEgMg1jOBZe7zHJwTrAh4BYj0OLbxwHq3HV8HBgVaGwL3AVuBfOA5INLrdgQW44xZtOP8sVrQU7sBgnPn3Q5gE84dUF7FWITTz37wnHncb/973Bi3AbO9ivGI7buAZC/b8WgPm2LCGGOCXLB0DRljjOmBJQJjjAlylgiMMSbIWSIwxpggZ4nAGGOCnCUCY1wi0ikin/o9em2iOhHJ6m52SmMCQdjRdzEmaDSr6nivgzCmv9kVgTFHISK7ROS3IrJJRD4WkRPc9VkistKdV36FiAx116e68+TnuY/p7qFCReRP4tQl+IeIDHD3XyhOTYqNIvKSR2/TBDFLBMYcMuCIrqHL/LbVqerJwCM4M7ICPAw8o868+C8Ai9z1i4B3VXUczrxHBe76EcCjqnoSUAtc4q6/C5jgHueHffXmjOmJfbPYGJeINKpqbDfrdwFnq+pn7iSBe1U1SUSqgG+paru7vlxVk0WkEshQ1Va/Y2QBy9Up+IKI3AmEq+qvROQtoBFneozXVbWxj9+qMYexKwJjjo328PzLaPV73smhMbrv4sw/MxFY5zcjqTH9whKBMcfmMr9/17jPP8SZlRVgPvCe+3wFcAN01XuO7+mgIhICZKrqKuBOIB743FWJMX3JPnkYc8gAEfnUb/ktVT14C+kgEdmI86l+nrvuZpzKaHfgVEm7xl1/C/CEiCzA+eR/A87slN0JBZ53k4UAi9QptWlMv7ExAmOOwh0jmKyqVV7HYkxfsK4hY4wJcnZFYIwxQc6uCIwxJshZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbI/T+i6nZ1Glja3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(150)),train_loss, label='Training Loss')\n",
    "plt.plot(list(range(150)),valid_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('images_model/train_batch_dropout_150.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model (model, test_num, X):\n",
    "    start_time = time.time()\n",
    "    Y_output = []\n",
    "    count = 0\n",
    "    totcount = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(test_num):\n",
    "            # get the inputs\n",
    "            inputs = X[i]\n",
    "            outputs = model(inputs)\n",
    "            Y_output.append(outputs)\n",
    "\n",
    "    print (\"Time taken in Testing {0}\".format((time.time() - start_time)))\n",
    "    return torch.stack(Y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "|Load from:  dataset/seq4\n",
      "----------------------------------------------------------------------\n",
      "|    Loading images from:  dataset/seq4/images\n",
      "|    Mean-normalizing ...\n",
      "|    Mean: [0.34079915 0.32100374 0.28959265]\n",
      "|    Done\n",
      "|    Images count :  368\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|    Pose from:  dataset/seq4/poses.csv\n",
      "|        Poses count:  368\n",
      "----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "---------------------------------------------------\n",
      "|   Total Images:  1\n",
      "|   Total Odometry:  1\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X,y = VODataLoader(datapath='dataset', test=True, seq='4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0] = X[0].view(-1,1,6,144,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([368, 1, 6, 144, 256])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Testing 43.96518087387085\n"
     ]
    }
   ],
   "source": [
    "y_out = testing_model(model,X[0].size(0),X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[0].view(-1,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([368, 1, 6])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([368, 1, 6])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "Accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions to get accuracy\n",
    "def get_accuracy(outputs, labels, batch_size):\n",
    "    diff =0\n",
    "    for i in range(batch_size):\n",
    "        out = (outputs[i].detach().numpy())[0]\n",
    "        lab = (labels[i].detach().numpy())[0]\n",
    "\n",
    "        diff+=get_mse_diff(out,lab)\n",
    "        \n",
    "    print(\"Accuracy : \",(1 -diff/(batch_size))*100,\"%\")\n",
    "    \n",
    "def get_mse_diff(x,y):\n",
    "    diff= 0\n",
    "    for i in range(6):\n",
    "        diff += (x[i]-y[i]) ** 2\n",
    "    return diff/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  68.11536534849523 %\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(y_out, y, y.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_acc(outputs, labels, batch_size):\n",
    "    diff =0\n",
    "    for i in range(batch_size):\n",
    "        out = (outputs[i].detach().numpy())[0]\n",
    "        lab = (labels[i].detach().numpy())[0]\n",
    "\n",
    "        diff+=get_mse_pos(out,lab)\n",
    "        \n",
    "    print(\"Accuracy : \",(1 -diff/(batch_size))*100,\"%\")\n",
    "\n",
    "def get_mse_pos(x,y):\n",
    "    diff= 0\n",
    "    for i in range(3):\n",
    "        diff += (x[i]-y[i]) ** 2\n",
    "    return diff/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  36.71617744378902 %\n"
     ]
    }
   ],
   "source": [
    "position_acc(y_out, y, y.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_acc(outputs, labels, batch_size):\n",
    "    diff =0\n",
    "    for i in range(batch_size):\n",
    "        out = (outputs[i].detach().numpy())[0]\n",
    "        lab = (labels[i].detach().numpy())[0]\n",
    "\n",
    "        diff+=get_mse_ang(out,lab)\n",
    "        \n",
    "    print(\"Accuracy : \",(1 -diff/(batch_size))*100,\"%\")\n",
    "\n",
    "def get_mse_ang(x,y):\n",
    "    diff= 0\n",
    "    for i in range(3,6):\n",
    "        diff += (x[i]-y[i]) ** 2\n",
    "    return 100 * (diff/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  51.45532532014779 %\n"
     ]
    }
   ],
   "source": [
    "angle_acc(y_out, y, y.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/deepvo-dropout-150.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ori = [y[0][0][0].item()]\n",
    "y_ori = [y[0][0][1].item()]\n",
    "for i in range(1,len(y)):\n",
    "    out = y[i]\n",
    "    out = (out.detach().numpy())[0]\n",
    "    x_ori.append(x_ori[i-1] + out[0].item())\n",
    "    y_ori.append(y_ori[i-1] + out[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o = [y_out[0][0][0].item()]\n",
    "y_o = [y_out[0][0][1].item()]\n",
    "for i in range(len(y_out)):    \n",
    "    out = y_out[i]\n",
    "    out = (out.detach().numpy())[0]\n",
    "    x_o.append(x_o[i-1] + out[0].item())\n",
    "    y_o.append(y_o[i-1] + out[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x72ae0ff98>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_ori,y_ori, label='Ground Truth')\n",
    "plt.plot(x_ori[0],y_ori[0],marker='x')\n",
    "plt.plot(x_o,y_o, label='Odometry')\n",
    "plt.plot(x_o[0],y_o[0],marker='x')\n",
    "plt.legend()\n",
    "plt.savefig('images_model/testeSeq5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
